# Results

```{r}
library(tidyverse)
library(dplyr)

survey <- read.csv('data/survey_results_public.csv')
schema <- read.csv('data/survey_results_schema.csv')

# ncol(survey)
# nrow(survey)

keep <- c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'YearsCode', 'YearsCodePro', 'DevType', 'Country', 'ConvertedCompYearly', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'WorkExp', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'Industry', 'JobSat', 'SurveyLength', 'SurveyEase')


selected <- survey |> dplyr::select(all_of(keep))

# colSums(is.na(selected))
# colMeans(is.na(selected)) * 100

selected <- selected |>
  mutate(across(c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'DevType', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'JobSat', 'SurveyLength', 'SurveyEase'), as.factor))
```

```{r}
library(ggplot2)
library(ggalluvial)
library(dplyr)
library(plotly)

AIThreat_order <- c('No', 'Unsure', 'Yes')
selected$AIThreat <- factor(selected$AIThreat, levels = AIThreat_order, ordered = TRUE)

AISent_order <- c('Very unfavorable', 'Unfavorable', 'Unsure', 'Indifferent', 'Favorable', 'Very favorable')
selected$AISent <- factor(selected$AISent, levels = AISent_order, ordered = TRUE)

AIComplex_order <- c('Very poor at handling complex tasks', 'Bad at handling complex tasks', 'Neither good or bad at handling complex tasks', 'Good, but not great at handling complex tasks', 'Very well at handling complex tasks')
selected$AIComplex <- factor(selected$AIComplex, levels = AIComplex_order, ordered = TRUE)

AIAcc_order <- c('Highly distrust', 'Somewhat distrust', 'Neither trust nor distrust', 'Somewhat trust', 'Highly trust')
selected$AIAcc <- factor(selected$AIAcc, levels = AIAcc_order, ordered = TRUE)

# Clean data to remove rows with NA values
filtered_data <- selected %>%
  filter(MainBranch == "I am a developer by profession") %>%
  filter(!is.na(AISelect) & !is.na(AISent) & !is.na(AIAcc) & !is.na(AIComplex) & !is.na(AIThreat))

alluvial_data <- filtered_data |>
  group_by(AIThreat, AIComplex, AISent, AIAcc) |>
  summarise(Freq = n()) |>
  ungroup()

```

```{r}
#| fig-width: 12
#| fig-height: 10
ggplot(alluvial_data,
       aes(axis1 = AIThreat, axis2 = AIComplex, axis3 = AISent, axis4 = AIAcc, y = Freq)) +
  geom_alluvium(aes(fill = AIAcc), alpha = 0.8) +
  geom_stratum(color = "gray", fill = "lightgray", alpha = 0.9) +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), 
            size = 2.5, color = "black", vjust = -0.5) +
  scale_x_discrete(limits = c("AI Threat", "Complexity", "Sentiment", "Accuracy"),
                   expand = c(0.2, 0.2)) +
  scale_fill_brewer(palette = "RdYlBu", name = "Trust Level") +
  theme_minimal(base_size = 8) +
  labs(title = "Alluvial Diagram for Developers",
       x = NULL,
       y = "Frequency") -> p

ggplotly(p)
```
```{r}
distribution <- selected |>
  filter(!is.na(AIThreat) & !is.na(Industry)) |>
  group_by(Industry, AIThreat) |>
  summarize(Count = n()) |>
  ungroup() |>
  group_by(Industry) |>
  mutate(Percent = Count / sum(Count) * 100) |>
  ungroup()

ggplot(distribution, aes(x = reorder(Industry, -Percent), y = Percent, fill = AIThreat)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Distribution of AI Threat by Industry",
    x = "Industry",
    y = "Percentage",
    fill = "AI Threat"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```
```{r}
# | fig-width: 15
# | fig-width: 10

SOVisitFreq_order <- c('Less than once per month or monthly', 'A few times per month or weekly', 'A few times per week', 'Daily or almost daily', 'Multiple times per day')
selected$SOVisitFreq <- factor(selected$SOVisitFreq, levels = SOVisitFreq_order, ordered = TRUE)

SOPartFreq_order <- c('I have never participated in Q&A on Stack Overflow', 'Less than once per month or monthly', 'A few times per month or weekly', 'A few times per week', 'Daily or almost daily', 'Multiple times per day')
selected$SOPartFreq <- factor(selected$SOPartFreq, levels = SOPartFreq_order, ordered = TRUE)


filtered <- selected |> 
  filter(!is.na(SOVisitFreq) & !is.na(SOPartFreq))

filtered
ggplot(filtered, aes(x = SOVisitFreq, y = SOPartFreq)) +
  geom_jitter(alpha=0.04) +
  labs(
    x = "Stack Overflow Visits",
    y = "Stack Overflow Participation"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```


```{r}
library(forcats)

# Reorder DevType and place NA at the bottom
avg_years_code_pro <- selected %>%
  group_by(DevType) %>%
  summarize(avg_years_code_pro = mean(as.numeric(YearsCodePro), na.rm = TRUE))

avg_years_code_pro <- avg_years_code_pro %>%
  mutate(DevType = fct_explicit_na(DevType, na_level = "NA")) %>%
  mutate(DevType = fct_rev(DevType))  # Reverse factor levels

# Create the Cleveland dot plot
ggplot(avg_years_code_pro, aes(x = avg_years_code_pro, y = reorder(DevType, avg_years_code_pro))) +
  geom_point(color = "skyblue", size = 2) +  # Use points instead of bars
  labs(x = "Average Years of Professional Coding", y = "Developer Type", 
       title = "Average Years of Professional Coding by Developer Type") +
  theme_minimal() +  # Cleaner theme
  theme(axis.text.y = element_text(size = 10),  # Adjust y-axis text size
        axis.title = element_text(size = 12))  # Adjust axis title size

```
This graph represents and confirms what is already suspected, those with most years of professional coding experience are at higher positions like C-Suite, Managers, Product Managers whereas those with lower years of coding experience tend to be Students, Data Analysts, Designers etc.
Higher Experience Roles: C-Suite Executives oversee company-wide, strategy, budgeting, and long-term planning, responsibilities often gained after years of technical and managerial experience.
Product Managers need domain knowledge and business acumen, skills that are developed through years of cross-functional experience.

Lower Experience Roles: These roles often serve as entry-level positions or focus on specific aspects of tech projects without requiring extensive coding experience.
Students are just beginning their journey and likely still developing coding expertise through education and internships.
Data Analysts often rely more on tools like Excel, SQL, and Tableau rather than programming-heavy workflows, making these roles accessible to those with foundational coding knowledge.
Designers focus on user interfaces and experiences, requiring creativity and knowledge of design tools more than coding proficiency.


```{r}
#| fig-width: 12
SOVisitFreq_order <- c('Less than once per month or monthly', 'A few times per month or weekly', 'A few times per week', 'Daily or almost daily', 'Multiple times per day')
selected$SOVisitFreq <- factor(selected$SOVisitFreq, levels = SOVisitFreq_order, ordered = TRUE)

filtered_data <- selected |>
  filter(!is.na(AISelect) & !is.na(SOVisitFreq))

contingency_table <- table(filtered_data$SOVisitFreq, filtered_data$AISelect)

mosaicplot(contingency_table, color=TRUE, shade=TRUE, las = 1, main='Relationship between using SO and using AI')
```

```{r}
require(HH)
require(grid)
require(lattice)
require(latticeExtra)

df_long <- selected %>%
  pivot_longer(cols = starts_with("Knowledge_"),
               names_to = "Question",
               values_to = "Response")

df_counts <- df_long %>%
  count(Question, Response) %>%
  pivot_wider(names_from = Response, values_from = n, values_fill = list(n = 0))

likert(Question ~ .,data=df_counts, ylab=NULL, ReferenceZero=3,
  as.percent=TRUE,
  main = list("Team-Related Questions",x=unit(.55, "npc")),
   xlim=c(-40,-20,0,20,40,60,80,100), strip=FALSE,
   par.strip.text=list(cex=.7))
```

```{r}
library(viridis)
library(plotly)

AI_survey <- read.csv('data/parsed_AItools.csv')
AI <- subset(AI_survey, select = -X)

data_long <- AI %>%
  pivot_longer(cols = -index, names_to = "category", values_to = "value")

ggplot(data_long, aes(x = index, y = category, fill = value)) +
  geom_tile() +
  scale_fill_viridis(option = "C") +  # Color scale
  labs(x = "Development Workflow", y = "AI integration interest", title = "Interest in Integrating AI into Development Activities") +
  scale_y_discrete(labels = c("Currently.Using" = "Currently using", "Interested.in.Using" = "Interested in using", "Not.interested.in.Using" = "Not interested in using")) +  # Relabel y-axis
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
ggplot(selected, aes(x = AISelect, y = Age)) +
  geom_jitter(aes(color = AISelect), width = 0.1, height = 0.1, alpha = 0.05) +
  theme_minimal() +
  labs(title = "Jitter Plot of AISelect vs Age",
       x = "AISelect",
       y = "Age")
```

```{r fig.width= 10}

ggplot(selected, aes(x = DevType, fill = RemoteWork)) +
  geom_bar(position = "fill") +
  labs(x = "Developer Type", y = "Proportion of Remote Work", 
       title = "Proportion of Remote Work by Developer Type") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Roles such as Data Scientist or Machine Learning Specialist, Cloud Infrastructure Engineer, and Developer - Backend have significant proportions of employees working fully remote, indicating these roles are well-suited for remote work environments.
Hybrid work is the most common mode for many roles, such as Product Manager, Full-stack Developer, and Site Reliability Engineer, indicating a balanced approach where both remote and in-person presence are valued.
In-person work is seen more in roles like Hardware Engineer, Engineering Manager, and System Administrator, which may require physical presence due to the nature of their responsibilities, such as managing physical systems or hardware.
```{r}
ggplot(selected, aes(x = as.factor(AISelect), y = as.numeric(JobSat))) +
  geom_jitter(aes(), alpha = 0.1, width = 0.2) +  # Add jitter for better visibility
  labs(x = "AI Tool Selection", y = "Job Satisfaction",
       title = "AI Tool Usage vs Job Satisfaction by Stack overflow visit freq") +
  facet_wrap(~ SOVisitFreq) +  # Facet by RemoteWork status
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
Individuals who selected Yes for AI tool usage generally show high job satisfaction across all visit frequencies.
Those planning to use AI tools soon seem to have slightly lower job satisfaction compared to current users but higher satisfaction than those not using AI tools.
Job satisfaction appears distributed similarly across different Stack Overflow visit frequencies.
Frequent visitors exhibit a larger spread of job satisfaction, potentially indicating diverse user experiences.
Denser areas in each plot indicate where most responses are concentrated. 
"Yes" under AI Tool Selection has a higher density at the top of the y-axis, suggesting a positive association between AI tool usage and job satisfaction.
This analysis suggests that using AI tools is associated with higher job satisfaction, regardless of Stack Overflow visit frequency.


```{r}
ggplot(selected, aes(x = SOPartFreq, fill = RemoteWork)) +
  geom_bar(position = "dodge", color = "black") +
  labs(x = "Participation Frequency", 
       y = "Count", 
       fill = "Remote Work Setup",
       title = "Participation Frequency vs. Remote Work Setup") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
The Hybrid (some remote, some in-person) setup is the most frequent across all participation categories. 
In-person workers generally participate less frequently, with lower counts in all categories except for "Less than once per month or monthly."
The Remote group has a significant number of participants, particularly in the "Multiple times per day" and "Daily or almost daily" categories, but still lower than the Hybrid group.
"A few times per week" and "Less than once per month or monthly" show low levels of participation, especially in the In-person group, indicating less frequent participation in Stack Overflow for those working primarily in-person.
The "I have never participated in Q&A on Stack Overflow" category shows a notable number of In-person workers, suggesting lower engagement from those not working remotely.

```{r}
selected_vf_pf <- selected %>%
  filter(!is.na(SOVisitFreq) & !is.na(SOPartFreq))

# Create the plot
ggplot(selected_vf_pf, aes(x = SOVisitFreq, fill = SOPartFreq)) +
  geom_bar(position = "fill", color = "black") +
  labs(x = "Visit Frequency", 
       y = "Proportion", 
       fill = "Participation Frequency",
       title = "Relationship Between Visit and Participation Frequency") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```
For those visiting "Once per month or monthly," a significant portion has never participated, or participates less than once per month. This suggests that infrequent visitors are less likely to engage actively.
As visit frequency increases to "A few times per month or weekly," there is a noticeable increase in participation, particularly in the "A few times per week" category. This indicates that more frequent visits are associated with higher engagement.
For those visiting "Daily or almost daily," participation is more evenly distributed across different frequencies, with a notable increase in daily participation.
The category "Multiple times per day" shows a high level of active participation, with many users participating multiple times daily.
The proportion of users who have never participated decreases as visit frequency increases.
Users visiting more frequently tend to participate more actively. This is evident from the increasing proportions in categories like "Daily or almost daily" and "Multiple times per day" as visit frequency increases.

```{r}
library(ggplot2)
library(dplyr)

# Prepare data: Count frequency of combinations of AIThreat and AISent
ai_threat_sentiment <- selected %>%
  filter(!is.na(AIThreat) & !is.na(AISent)) %>%
  count(AIThreat, AISent)

# Create a stacked bar plot
ggplot(ai_threat_sentiment, aes(x = AISent, y = n, fill = AIThreat)) +
  geom_bar(stat = "identity") +
  labs(title = "AI Threat Perception vs AI Sentiment",
       x = "AI Sentiment",
       y = "Count",
       fill = "AI Threat") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```
```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(viridis)
library(maps)

# Assume 'selected' is the dataset you're working with

# Step 1: Summarize the average Job Satisfaction by country
job_sat_data <- selected %>%
  filter(!is.na(JobSat)) %>%  # Remove rows with missing job satisfaction data
  group_by(Country) %>%  # Group by country
  summarise(AvgJobSat = mean(as.numeric(as.character(JobSat)), na.rm = TRUE))  # Calculate average job satisfaction

# Step 2: Get map data
map_data <- map_data("world")

# Step 3: Merge the map data with the summarized job satisfaction data
merged_data <- left_join(map_data, job_sat_data, by = c("region" = "Country"))

# Step 4: Plot the choropleth map
ggplot(merged_data, aes(x = long, y = lat, group = group, fill = AvgJobSat)) +
  geom_polygon(color = "black", size = 0.1) +  # Draw polygons with black borders
  scale_fill_viridis(option = "magma", direction = -1, name = "Avg Job Sat") +  # Use 'viridis' color scale for better visibility
  theme_void() +  # Remove axis and grid lines for a cleaner map
  labs(title = "Average Job Satisfaction by Country")  # Add title

```
```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(viridis)
library(maps)

# Step 1: Summarize the proportion of people who think AI is a threat by country
ai_threat_data <- selected %>%
  filter(!is.na(AIThreat)) %>%  # Remove rows with missing data
  group_by(Country) %>%  # Group by country
  summarise(
    ThreatCount = sum(AIThreat == "Yes", na.rm = TRUE),  # Count how many think AI is a threat
    TotalCount = n(),  # Count the total number of responses
    ProportionThreat = ThreatCount / TotalCount * 100  # Calculate the proportion
  )

# Step 2: Get map data
map_data <- map_data("world")

# Step 3: Merge the map data with the summarized AI threat data
merged_data <- left_join(map_data, ai_threat_data, by = c("region" = "Country"))

# Step 4: Plot the choropleth map
ggplot(merged_data, aes(x = long, y = lat, group = group, fill = ProportionThreat)) +
  geom_polygon(color = "black", size = 0.1) +  # Draw polygons with black borders
  scale_fill_viridis(option = "magma", direction = -1, name = "AI Threat Proportion (%)") +  # Use 'viridis' color scale
  theme_void() +  # Remove axis and grid lines for a cleaner map
  labs(title = "Proportion of People Who Think AI is a Threat by Country")  # Add title

```



```{r fig.width=10}
ai_next <- read.csv('data/ai_next.csv')

likert(index ~ .,data=ai_next, ylab=NULL, ReferenceZero=3,
  as.percent=TRUE,
  main = list("Future AI integration into workflow",x=unit(.55, "npc")),
  strip=FALSE,
   par.strip.text=list(cex=.7))

```

```{r fig.height=10}
library(ggplot2)

# Define the correct order of education levels
selected$EdLevel <- factor(selected$EdLevel, 
                           levels = c("Primary/elementary school", 
                                      "Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)",
                                      "Some college/university study without earning a degree",
                                      "Associate degree (A.A., A.S., etc.)",
                                      "Bachelor’s degree (B.A., B.S., B.Eng., etc.)",
                                      "Master’s degree (M.A., M.S., M.Eng., MBA, etc.)",
                                      "Professional degree (JD, MD, Ph.D, Ed.D, etc.)",
                                      "Something else"))


ggplot(selected, aes(x = EdLevel)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(
    title = "Distribution of Highest Level of Formal Education",
    x = "Education Level",
    y = "Count"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```
From this graph it can be seen that the most common highest qualification for people is a Bachelor’s degree, followed by a Master’s degree.
Over 40,000 individuals have achieved higher education degrees (Bachelor’s, Master’s, and Professional degrees). This suggests a strong focus on advanced education within the community.
 Approximately 16,000+ individuals fall into categories such as pre-primary, secondary, some college without a degree, associate degrees, and "something else." This indicates that fewer people stop their formal education at these levels.
The substantial number of Master's and Professional degrees signifies a trend toward pursuing advanced education.

```{r}
# Install and load treemap package
library(treemap)

# Create a treemap for education levels
industry_counts_df <- as.data.frame(table(selected$Industry))

# Create the treemap with labels and legend
treemap(industry_counts_df,
        index = "Var1",  # Category variable
        vSize = "Freq",  # Size based on frequency
        vColor = "Freq", # Color based on frequency
        palette = "Blues", # Customize the color palette
        draw = TRUE,
        title = "Distribution of Industries of Respondents",
        fontsize.title = 16,  # Adjust title font size
        fontsize.labels = 12, # Adjust labels font size
        fontsize.legend = 10, # Adjust legend font size
        legend = TRUE,  # Show legend
        border.col = "white" # White border around the tiles for better visibility
)

```
Software Development is the largest sector, occupying a significant portion of the distribution. This could reflect the high engagement of software developers in surveys like these.
Fintech and Internet, Telecomm or Information Services are also prominent, reflecting the growing importance of digital financial services and communication technologies.
Healthcare and Retail and Consumer Services are moderately sized.
Sectors like Banking/Financial Services, Manufacturing, and Government have smaller representations, suggesting either niche markets or less emphasis compared to larger sectors.
Media & Advertising Services, Higher Education, and Transportation, or Supply Chain are similarly sized.
The inclusion of non-tech industries like Healthcare, Government, and Retail shows that technology professionals are present across diverse fields. The dominance of tech industries highlights the survey's appeal to respondents working in these domains.


```{r fig.height=10}
ggplot(selected, aes(x = Age)) +
  geom_bar(fill='lightblue') +
  facet_wrap(~ MainBranch) +
  theme_minimal() +
  labs(title = "Distribution of Age by Main Branch",
       x = "Age",
       y = "Count")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
The majority of respondents are professional developers, particularly in the 18-24 and 25-34 age groups. This indicates a strong presence of young professionals in the tech industry.
Those who code primarily as a hobby or are learning to code are significantly fewer compared to professional developers. However, they are present across all age groups, with a slight concentration in younger demographics.
Individuals who used to be developers but no longer are form a very small portion of the sample, suggesting that career transitions out of development might be less common or that they move into roles still related to technology.
People who code as part of their work or studies but not as their primary role are spread across various age groups, with notable numbers in the 25-34 and 35-44 age ranges. This reflects the interdisciplinary nature of coding skills in various professions.
The 18-24 and 25-34 age groups dominate across most categories, highlighting these as key ages for both entering and establishing a career in coding.


