# Results

```{r}
library(tidyverse)
library(dplyr)

survey <- read.csv('data/survey_results_public.csv')
schema <- read.csv('data/survey_results_schema.csv')

# ncol(survey)
# nrow(survey)

keep <- c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'YearsCode', 'YearsCodePro', 'DevType', 'Country', 'ConvertedCompYearly', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'WorkExp', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'Industry', 'JobSat', 'SurveyLength', 'SurveyEase')


selected <- survey |> dplyr::select(all_of(keep))

# colSums(is.na(selected))
# colMeans(is.na(selected)) * 100

selected <- selected |>
  mutate(across(c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'DevType', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'JobSat', 'SurveyLength', 'SurveyEase'), as.factor))
```

```{r}
library(ggplot2)
library(ggalluvial)
library(dplyr)
library(plotly)

AIThreat_order <- c('No', 'Unsure', 'Yes')
selected$AIThreat <- factor(selected$AIThreat, levels = AIThreat_order, ordered = TRUE)

AISent_order <- c('Very unfavorable', 'Unfavorable', 'Unsure', 'Indifferent', 'Favorable', 'Very favorable')
selected$AISent <- factor(selected$AISent, levels = AISent_order, ordered = TRUE)

AIComplex_order <- c('Very poor at handling complex tasks', 'Bad at handling complex tasks', 'Neither good or bad at handling complex tasks', 'Good, but not great at handling complex tasks', 'Very well at handling complex tasks')
selected$AIComplex <- factor(selected$AIComplex, levels = AIComplex_order, ordered = TRUE)

AIAcc_order <- c('Highly distrust', 'Somewhat distrust', 'Neither trust nor distrust', 'Somewhat trust', 'Highly trust')
selected$AIAcc <- factor(selected$AIAcc, levels = AIAcc_order, ordered = TRUE)

# Clean data to remove rows with NA values
filtered_data <- selected %>%
  filter(MainBranch == "I am a developer by profession") %>%
  filter(!is.na(AISelect) & !is.na(AISent) & !is.na(AIAcc) & !is.na(AIComplex) & !is.na(AIThreat))

alluvial_data <- filtered_data |>
  group_by(AIThreat, AIComplex, AISent, AIAcc) |>
  summarise(Freq = n()) |>
  ungroup()

```

```{r}
#| fig-width: 12
#| fig-height: 10
ggplot(alluvial_data,
       aes(axis1 = AIThreat, axis2 = AIComplex, axis3 = AISent, axis4 = AIAcc, y = Freq)) +
  geom_alluvium(aes(fill = AIAcc), alpha = 0.8) +
  geom_stratum(color = "gray", fill = "lightgray", alpha = 0.9) +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), 
            size = 2.5, color = "black", vjust = -0.5) +
  scale_x_discrete(limits = c("AI Threat", "Complexity", "Sentiment", "Accuracy"),
                   expand = c(0.2, 0.2)) +
  scale_fill_brewer(palette = "RdYlBu", name = "Trust Level") +
  theme_minimal(base_size = 8) +
  labs(title = "Alluvial Diagram for Developers",
       x = NULL,
       y = "Frequency") -> p

ggplotly(p)
```
```{r}
distribution <- selected |>
  filter(!is.na(AIThreat) & !is.na(Industry)) |>
  group_by(Industry, AIThreat) |>
  summarize(Count = n()) |>
  ungroup() |>
  group_by(Industry) |>
  mutate(Percent = Count / sum(Count) * 100) |>
  ungroup()

ggplot(distribution, aes(x = reorder(Industry, -Percent), y = Percent, fill = AIThreat)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Distribution of AI Threat by Industry",
    x = "Industry",
    y = "Percentage",
    fill = "AI Threat"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```
```{r}
# | fig-width: 15
# | fig-width: 10

SOVisitFreq_order <- c('Less than once per month or monthly', 'A few times per month or weekly', 'A few times per week', 'Daily or almost daily', 'Multiple times per day')
selected$SOVisitFreq <- factor(selected$SOVisitFreq, levels = SOVisitFreq_order, ordered = TRUE)

SOPartFreq_order <- c('I have never participated in Q&A on Stack Overflow', 'Less than once per month or monthly', 'A few times per month or weekly', 'A few times per week', 'Daily or almost daily', 'Multiple times per day')
selected$SOPartFreq <- factor(selected$SOPartFreq, levels = SOPartFreq_order, ordered = TRUE)


filtered <- selected |> 
  filter(!is.na(SOVisitFreq) & !is.na(SOPartFreq))

filtered
ggplot(filtered, aes(x = SOVisitFreq, y = SOPartFreq)) +
  geom_jitter(alpha=0.04) +
  labs(
    x = "Stack Overflow Visits",
    y = "Stack Overflow Participation"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```


```{r}
library(forcats)

# Reorder DevType and place NA at the bottom
avg_years_code_pro <- selected %>%
  group_by(DevType) %>%
  summarize(avg_years_code_pro = mean(as.numeric(YearsCodePro), na.rm = TRUE))

avg_years_code_pro <- avg_years_code_pro %>%
  mutate(DevType = fct_explicit_na(DevType, na_level = "NA")) %>%
  mutate(DevType = fct_rev(DevType))  # Reverse factor levels

# Create the Cleveland dot plot
ggplot(avg_years_code_pro, aes(x = avg_years_code_pro, y = reorder(DevType, avg_years_code_pro))) +
  geom_point(color = "skyblue", size = 2) +  # Use points instead of bars
  labs(x = "Average Years of Professional Coding", y = "Developer Type", 
       title = "Average Years of Professional Coding by Developer Type") +
  theme_minimal() +  # Cleaner theme
  theme(axis.text.y = element_text(size = 10),  # Adjust y-axis text size
        axis.title = element_text(size = 12))  # Adjust axis title size

```

```{r}
#| fig-width: 12
SOVisitFreq_order <- c('Less than once per month or monthly', 'A few times per month or weekly', 'A few times per week', 'Daily or almost daily', 'Multiple times per day')
selected$SOVisitFreq <- factor(selected$SOVisitFreq, levels = SOVisitFreq_order, ordered = TRUE)

filtered_data <- selected |>
  filter(!is.na(AISelect) & !is.na(SOVisitFreq))

contingency_table <- table(filtered_data$SOVisitFreq, filtered_data$AISelect)

mosaicplot(contingency_table, color=TRUE, shade=TRUE, las = 1, main='Relationship between using SO and using AI')
```

```{r}
require(HH)
require(grid)
require(lattice)
require(latticeExtra)

df_long <- selected %>%
  pivot_longer(cols = starts_with("Knowledge_"),
               names_to = "Question",
               values_to = "Response")

df_counts <- df_long %>%
  count(Question, Response) %>%
  pivot_wider(names_from = Response, values_from = n, values_fill = list(n = 0))

likert(Question ~ .,data=df_counts, ylab=NULL, ReferenceZero=3,
  as.percent=TRUE,
  main = list("Team-Related Questions",x=unit(.55, "npc")),
   xlim=c(-40,-20,0,20,40,60,80,100), strip=FALSE,
   par.strip.text=list(cex=.7))
```

```{r}
library(viridis)
library(plotly)

AI_survey <- read.csv('data/parsed_AItools.csv')
AI <- subset(AI_survey, select = -X)

data_long <- AI %>%
  pivot_longer(cols = -index, names_to = "category", values_to = "value")

ggplot(data_long, aes(x = index, y = category, fill = value)) +
  geom_tile() +
  scale_fill_viridis(option = "C") +  # Color scale
  labs(x = "Development Workflow", y = "AI integration interest", title = "Interest in Integrating AI into Development Activities") +
  scale_y_discrete(labels = c("Currently.Using" = "Currently using", "Interested.in.Using" = "Interested in using", "Not.interested.in.Using" = "Not interested in using")) +  # Relabel y-axis
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
ggplot(selected, aes(x = AISelect, y = Age)) +
  geom_jitter(aes(color = AISelect), width = 0.1, height = 0.1, alpha = 0.05) +
  theme_minimal() +
  labs(title = "Jitter Plot of AISelect vs Age",
       x = "AISelect",
       y = "Age")
```

```{r fig.width= 10}

ggplot(selected, aes(x = DevType, fill = RemoteWork)) +
  geom_bar(position = "fill") +
  labs(x = "Developer Type", y = "Proportion of Remote Work", 
       title = "Proportion of Remote Work by Developer Type") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
ggplot(selected, aes(x = as.factor(AISelect), y = as.numeric(JobSat))) +
  geom_jitter(aes(), alpha = 0.1, width = 0.2) +  # Add jitter for better visibility
  labs(x = "AI Tool Selection", y = "Job Satisfaction",
       title = "AI Tool Usage vs Job Satisfaction by Stack overflow visit freq") +
  facet_wrap(~ SOVisitFreq) +  # Facet by RemoteWork status
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


```{r}
ggplot(selected, aes(x = SOPartFreq, fill = RemoteWork)) +
  geom_bar(position = "dodge", color = "black") +
  labs(x = "Participation Frequency", 
       y = "Count", 
       fill = "Remote Work Setup",
       title = "Participation Frequency vs. Remote Work Setup") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
selected_vf_pf <- selected %>%
  filter(!is.na(SOVisitFreq) & !is.na(SOPartFreq))

# Create the plot
ggplot(selected_vf_pf, aes(x = SOVisitFreq, fill = SOPartFreq)) +
  geom_bar(position = "fill", color = "black") +
  labs(x = "Visit Frequency", 
       y = "Proportion", 
       fill = "Participation Frequency",
       title = "Relationship Between Visit and Participation Frequency") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(viridis)
library(maps)

# Load map data
map_data <- map_data("world")

# Summarize Job Satisfaction data by country
job_sat_data <- selected %>%
  filter(!is.na(JobSat_Grouped)) %>% # Remove missing values
  group_by(Country, JobSat_Grouped) %>%
  tally() %>%
  spread(JobSat_Grouped, n, fill = 0) %>%
  mutate(
    Total = High + Medium + Low,
    High_Proportion = High / Total * 100 # Proportion of "High" satisfaction
  )

# Merge map data with summarized job satisfaction data
merged_data <- left_join(map_data, job_sat_data, by = c("region" = "Country"))

# Plot the choropleth map
ggplot(merged_data, aes(x = long, y = lat, group = group, fill = High_Proportion)) +
  geom_polygon(color = "black", size = 0.1) +
  scale_fill_viridis(option = "magma", direction = -1, name = "High Job Sat (%)") +
  theme_void() +
  labs(title = "Job Satisfaction (High) Proportion by Country")
```
```{r}
library(ggplot2)
library(dplyr)

# Prepare data: Count frequency of combinations of AIThreat and AISent
ai_threat_sentiment <- selected %>%
  filter(!is.na(AIThreat) & !is.na(AISent)) %>%
  count(AIThreat, AISent)

# Create a stacked bar plot
ggplot(ai_threat_sentiment, aes(x = AISent, y = n, fill = AIThreat)) +
  geom_bar(stat = "identity") +
  labs(title = "AI Threat Perception vs AI Sentiment",
       x = "AI Sentiment",
       y = "Count",
       fill = "AI Threat") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```
```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(viridis)
library(maps)

# Assume 'selected' is the dataset you're working with

# Step 1: Summarize the average Job Satisfaction by country
job_sat_data <- selected %>%
  filter(!is.na(JobSat)) %>%  # Remove rows with missing job satisfaction data
  group_by(Country) %>%  # Group by country
  summarise(AvgJobSat = mean(as.numeric(as.character(JobSat)), na.rm = TRUE))  # Calculate average job satisfaction

# Step 2: Get map data
map_data <- map_data("world")

# Step 3: Merge the map data with the summarized job satisfaction data
merged_data <- left_join(map_data, job_sat_data, by = c("region" = "Country"))

# Step 4: Plot the choropleth map
ggplot(merged_data, aes(x = long, y = lat, group = group, fill = AvgJobSat)) +
  geom_polygon(color = "black", size = 0.1) +  # Draw polygons with black borders
  scale_fill_viridis(option = "magma", direction = -1, name = "Avg Job Sat") +  # Use 'viridis' color scale for better visibility
  theme_void() +  # Remove axis and grid lines for a cleaner map
  labs(title = "Average Job Satisfaction by Country")  # Add title

```
```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(viridis)
library(maps)

# Step 1: Summarize the proportion of people who think AI is a threat by country
ai_threat_data <- selected %>%
  filter(!is.na(AIThreat)) %>%  # Remove rows with missing data
  group_by(Country) %>%  # Group by country
  summarise(
    ThreatCount = sum(AIThreat == "Yes", na.rm = TRUE),  # Count how many think AI is a threat
    TotalCount = n(),  # Count the total number of responses
    ProportionThreat = ThreatCount / TotalCount * 100  # Calculate the proportion
  )

# Step 2: Get map data
map_data <- map_data("world")

# Step 3: Merge the map data with the summarized AI threat data
merged_data <- left_join(map_data, ai_threat_data, by = c("region" = "Country"))

# Step 4: Plot the choropleth map
ggplot(merged_data, aes(x = long, y = lat, group = group, fill = ProportionThreat)) +
  geom_polygon(color = "black", size = 0.1) +  # Draw polygons with black borders
  scale_fill_viridis(option = "magma", direction = -1, name = "AI Threat Proportion (%)") +  # Use 'viridis' color scale
  theme_void() +  # Remove axis and grid lines for a cleaner map
  labs(title = "Proportion of People Who Think AI is a Threat by Country")  # Add title

```



```{r fig.width=10}
ai_next <- read.csv('data/ai_next.csv')

likert(index ~ .,data=ai_next, ylab=NULL, ReferenceZero=3,
  as.percent=TRUE,
  main = list("Future AI integration into workflow",x=unit(.55, "npc")),
  strip=FALSE,
   par.strip.text=list(cex=.7))

```

```{r fig.height=10}
library(ggplot2)

# Define the correct order of education levels
selected$EdLevel <- factor(selected$EdLevel, 
                           levels = c("Primary/elementary school", 
                                      "Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)",
                                      "Some college/university study without earning a degree",
                                      "Associate degree (A.A., A.S., etc.)",
                                      "Bachelor’s degree (B.A., B.S., B.Eng., etc.)",
                                      "Master’s degree (M.A., M.S., M.Eng., MBA, etc.)",
                                      "Professional degree (JD, MD, Ph.D, Ed.D, etc.)",
                                      "Something else"))


ggplot(selected, aes(x = EdLevel)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(
    title = "Distribution of Highest Level of Formal Education",
    x = "Education Level",
    y = "Count"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```
```{r}
# Install and load treemap package
library(treemap)

# Create a treemap for education levels
industry_counts_df <- as.data.frame(table(selected$Industry))

# Create the treemap with labels and legend
treemap(industry_counts_df,
        index = "Var1",  # Category variable
        vSize = "Freq",  # Size based on frequency
        vColor = "Freq", # Color based on frequency
        palette = "Blues", # Customize the color palette
        draw = TRUE,
        title = "Distribution of Industries of Respondents",


        fontsize.title = 16,  # Adjust title font size
        fontsize.labels = 12, # Adjust labels font size
        fontsize.legend = 10, # Adjust legend font size
        legend = TRUE,  # Show legend
        border.col = "white" # White border around the tiles for better visibility
)

```

