[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "StackOverflow 2024 Survey Analysis",
    "section": "",
    "text": "1 Introduction\nBefore OpenAI and other LLMs were built, StackOverflow was the go-to source for developers to have their questions answered. In May 2024 over 65,000 developers responded to Stack Overflow’s annual survey about coding, working, AI and how they feel about the industry. This data can provide valuable insights into the current state of the tech industry. As individuals who work in tech or aim to work in tech, understanding these trends is both interesting and essential These insights are crucial for understanding how the industry is evolving and how developers feel about the tools, skills, and environments shaping their work.\nQuestions we’re interested in:\n\nDemographics of respondents: to understand the landscape of users StackOverflow caters to\nPerspectives on AI: to understand developers’ views on AI in the workplace, especially in the world of generative AI as a threat to certain jobs\nStackOverflow usage: With the advent of GPT, LLama and other LLM’s, how developers’ perspectives on more “traditional” sources like StackOverflow are changing and whether it still adequately meets their needs.\n\n(As we explore the data further and discover patterns, we will refine and update our research questions.)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nThis is the link from which the data set has been obtained: Stack Overflow Survey 2024\nEvery May since 2011, Stack Overflow conducts an annual survey. The 2024 survey included data about coding, working, AI and Stack Overflow users’ profiles and perceptions in these domains. The data is collected by Stack Overflow via a Qualtrics survey, and is updated on a yearly basis. The survey follows a questionnaire style with different types of questions including single-choice, multi-select, and Likert scale questions, ranking scale, boolean and text-based.\nThe May 2024 survey had over 65,000 respondents. Stack Overflow publishes results as a data table with 114 features (engineered from 87 questions) and 65,437 rows. It additionally publishes a schema and the questionnaire itself.\nOne concern in terms of parsing is with regards to multi-select questions. Parsing these either result in adding multiple columns which will have many missing values or parsing them in all possible combinations which has little interpretability. Hence, to begin, we limit the inputs to our analysis to the other question types. Additionally, we went through the schema and have picked questions whose responses are relevant to our research questions.\nFinally, the data is downloaded into the ‘data’ folder and is imported using read.csv in R.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(dplyr)\n\nsurvey &lt;- read.csv('data/survey_results_public.csv')\nschema &lt;- read.csv('data/survey_results_schema.csv')\n\n# ncol(survey)\n# nrow(survey)\n\nkeep &lt;- c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'YearsCode', 'YearsCodePro', 'DevType', 'Country', 'ConvertedCompYearly', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'WorkExp', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'Industry', 'JobSat', 'SurveyLength', 'SurveyEase')\n\nselected &lt;- survey |&gt; dplyr::select(all_of(keep))\n\nselected &lt;- selected |&gt;\n  mutate(across(c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'DevType', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'JobSat', 'SurveyLength', 'SurveyEase'), as.factor))\n\n\n\n\nCode\nlibrary(ggplot2)\nmissing_counts &lt;- colSums(is.na(selected))\nmissing_percent &lt;- (missing_counts / nrow(selected)) * 100\nmissing_df &lt;- data.frame(\n  column = names(missing_counts),\n  missing_percent = missing_percent\n)\nmissing_df$column &lt;- factor(missing_df$column, levels = missing_df$column)\n\nggplot(missing_df, aes(x = column, y = missing_percent)) +\n  geom_bar(stat = \"identity\", fill='skyblue') +\n  labs(\n    title = \"Percentage of Missing Values per Column\",\n    x = \"Columns\",\n    y = \"Missing Values (%)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size=8)) +\n  scale_y_continuous(limits = c(0, 100))\n\n\n\n\n\n\n\n\n\nWe first look at the percentage of missing values in each of our selected columns. As is expected from an online questionnaire, there is a very high number of missing values with multiple columns crossing the 50% threshold as well. We observe that the ‘Check’ column, which was just a check to ensure that the participant was paying attention to the survey has zero missing values. Thus, we do not eliminate any rows based on this check. We also notice that the series of ‘Knowledge_’ questions, which all serve as part of a Likert-scale question have high missing values. These are probably a result of people skipping the question entirely.\nTo further check if there are any correlations between not answering certain types of questions, we plot a heatmap of correlations between missing values. We cannot compute correlations for Age, Check, and MainBranch since these questions have have no missing values.\n\n\nCode\nlibrary(reshape2)\n\n\n\nAttaching package: 'reshape2'\n\n\nThe following object is masked from 'package:tidyr':\n\n    smiths\n\n\nCode\nmissing_matrix &lt;- is.na(selected) * 1\nmissing_corr &lt;- cor(missing_matrix)\n\n\nWarning in cor(missing_matrix): the standard deviation is zero\n\n\nCode\nmissing_corr_melted &lt;- melt(missing_corr)\n\nggplot(missing_corr_melted, aes(Var1, Var2, fill = value)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient2(\n    low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0,\n    limit = c(-1, 1), space = \"Lab\", name = \"Correlation\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size=6),\n    axis.text.y = element_text(size=6)\n  ) +\n  labs(title = \"Correlation of Missing Values\", x = \"Columns\", y = \"Columns\")\n\n\n\n\n\n\n\n\n\nWe observe that, typically, blocks of questions have missing values. For instance, it seems that missing values are correlated in the professional-related questions, i.e. from the column ICorPM until the industry question. These are perhaps a result of the individual being a student or just a hobby-developer. Similarly, another block of correlation is observed for the AI-related questions. Thus, it seems that perhaps, when skipping, individuals skipped certain lines of questioning entirely.\nWe believe that we can retain value by keeping these rows with missing values since perhaps the missing values form clusters of individuals. We explore one other cause of missing values - fatigue. To check this, we plot the percent missing values over the questions in order that they were answered, faceted on their answer to one of the last questions – “How do you feel about the length of the survey this year?”\n\n\nCode\nselected$SurveyLength &lt;- fct_na_value_to_level(selected$SurveyLength)\n\nmissing_values &lt;- selected %&gt;%\n  group_by(SurveyLength) %&gt;%\n  summarise(across(everything(), ~ mean(is.na(.)))) %&gt;%\n  pivot_longer(cols = -SurveyLength, names_to = \"question\", values_to = \"missing_proportion\")\n\nmissing_values &lt;- missing_values %&gt;%\n  left_join(schema, by = c(\"question\" = \"qname\"))\n\nggplot(missing_values, aes(x = question, y = missing_proportion)) +\n  geom_line(group = 1, color = \"darkgrey\", size = 0.5) +\n  geom_point(aes(color = force_resp), size = 1.5) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = -0.01, size = 6)) +\n  labs(x = \"Survey Question\", y = \"Proportion of Missing Values\",\n       title = \"Missing Data Across Survey Questions by SurveyLength\",\n       color = \"Required Question\") +\n  facet_wrap(~ SurveyLength)\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nWe notice, as a general pattern, that the missing values have a somewhat upward trend as users progressed in the survey. As expected, the highest likelihood of missing values is when the last question is unanswered. Interestingly, those that thought the survey was “Too Short” had a higher proportion of missing values compared to those that thought it was “Too long”. Although somewhat counter intuitive, perhaps it is the fatigue from actually answering the questions that results in answering “Too long”, while not answering leads to believing it was too short.\nWe additionally look at data on whether the question is a required question. We notice that certain non-required questions also have very few missing values, indicating user keenness on answering these questions, such as their current development type (i.e. job) and questions regarding their experience with Stack Overflow. We also notice how even certain required questions have high missing values, which perhaps indicates a systemic flaw. We are considering dropping the rows where a required question was not answered, since this likely indicates an incomplete survey that was wrongly submitted.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(dplyr)\n\nsurvey &lt;- read.csv('data/survey_results_public.csv')\nschema &lt;- read.csv('data/survey_results_schema.csv')\n\n# ncol(survey)\n# nrow(survey)\n\nkeep &lt;- c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'YearsCode', 'YearsCodePro', 'DevType', 'Country', 'ConvertedCompYearly', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'WorkExp', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'Industry', 'JobSat', 'SurveyLength', 'SurveyEase')\n\n\nselected &lt;- survey |&gt; dplyr::select(all_of(keep))\n\n# colSums(is.na(selected))\n# colMeans(is.na(selected)) * 100\n\nselected &lt;- selected |&gt;\n  mutate(across(c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'DevType', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'JobSat', 'SurveyLength', 'SurveyEase'), as.factor))\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(ggalluvial)\nlibrary(dplyr)\nlibrary(plotly)\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n\nCode\nAIThreat_order &lt;- c('No', 'Unsure', 'Yes')\nselected$AIThreat &lt;- factor(selected$AIThreat, levels = AIThreat_order, ordered = TRUE)\n\nAISent_order &lt;- c('Very unfavorable', 'Unfavorable', 'Unsure', 'Indifferent', 'Favorable', 'Very favorable')\nselected$AISent &lt;- factor(selected$AISent, levels = AISent_order, ordered = TRUE)\n\nAIComplex_order &lt;- c('Very poor at handling complex tasks', 'Bad at handling complex tasks', 'Neither good or bad at handling complex tasks', 'Good, but not great at handling complex tasks', 'Very well at handling complex tasks')\nselected$AIComplex &lt;- factor(selected$AIComplex, levels = AIComplex_order, ordered = TRUE)\n\nAIAcc_order &lt;- c('Highly distrust', 'Somewhat distrust', 'Neither trust nor distrust', 'Somewhat trust', 'Highly trust')\nselected$AIAcc &lt;- factor(selected$AIAcc, levels = AIAcc_order, ordered = TRUE)\n\n# Clean data to remove rows with NA values\nfiltered_data &lt;- selected %&gt;%\n  filter(MainBranch == \"I am a developer by profession\") %&gt;%\n  filter(!is.na(AISelect) & !is.na(AISent) & !is.na(AIAcc) & !is.na(AIComplex) & !is.na(AIThreat))\n\nalluvial_data &lt;- filtered_data |&gt;\n  group_by(AIThreat, AIComplex, AISent, AIAcc) |&gt;\n  summarise(Freq = n()) |&gt;\n  ungroup()\n\n\n`summarise()` has grouped output by 'AIThreat', 'AIComplex', 'AISent'. You can\noverride using the `.groups` argument.\n\n\n\n\nCode\nggplot(alluvial_data,\n       aes(axis1 = AIThreat, axis2 = AIComplex, axis3 = AISent, axis4 = AIAcc, y = Freq)) +\n  geom_alluvium(aes(fill = AIAcc), alpha = 0.8) +\n  geom_stratum(color = \"gray\", fill = \"lightgray\", alpha = 0.9) +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum)), \n            size = 2.5, color = \"black\", vjust = -0.5) +\n  scale_x_discrete(limits = c(\"AI Threat\", \"Complexity\", \"Sentiment\", \"Accuracy\"),\n                   expand = c(0.2, 0.2)) +\n  scale_fill_brewer(palette = \"RdYlBu\", name = \"Trust Level\") +\n  theme_minimal(base_size = 8) +\n  labs(title = \"Alluvial Diagram for Developers\",\n       x = NULL,\n       y = \"Frequency\") -&gt; p\n\nggplotly(p)\n\n\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\n\n\n\n\n\n\n\n\nCode\ndistribution &lt;- selected |&gt;\n  filter(!is.na(AIThreat) & !is.na(Industry)) |&gt;\n  group_by(Industry, AIThreat) |&gt;\n  summarize(Count = n()) |&gt;\n  ungroup() |&gt;\n  group_by(Industry) |&gt;\n  mutate(Percent = Count / sum(Count) * 100) |&gt;\n  ungroup()\n\n\n`summarise()` has grouped output by 'Industry'. You can override using the\n`.groups` argument.\n\n\nCode\nggplot(distribution, aes(x = reorder(Industry, -Percent), y = Percent, fill = AIThreat)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    title = \"Distribution of AI Threat by Industry\",\n    x = \"Industry\",\n    y = \"Percentage\",\n    fill = \"AI Threat\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# | fig-width: 15\n\nSOVisitFreq_order &lt;- c('Less than once per month or monthly', 'A few times per month or weekly', 'A few times per week', 'Daily or almost daily', 'Multiple times per day')\nselected$SOVisitFreq &lt;- factor(selected$SOVisitFreq, levels = SOVisitFreq_order, ordered = TRUE)\n\nSOPartFreq_order &lt;- c('I have never participated in Q&A on Stack Overflow', 'Less than once per month or monthly', 'A few times per month or weekly', 'A few times per week', 'Daily or almost daily', 'Multiple times per day')\nselected$SOPartFreq &lt;- factor(selected$SOPartFreq, levels = SOPartFreq_order, ordered = TRUE)\n\n\nfiltered &lt;- selected |&gt; \n  filter(!is.na(SOVisitFreq) & !is.na(SOPartFreq))\n\nggplot(filtered, aes(x = SOVisitFreq, y = SOPartFreq)) +\n  geom_jitter(alpha=0.04) +\n  labs(\n    x = \"Stack Overflow Visits\",\n    y = \"Stack Overflow Participation\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(forcats)\n\n# Reorder DevType and place NA at the bottom\navg_years_code_pro &lt;- selected %&gt;%\n  group_by(DevType) %&gt;%\n  summarize(avg_years_code_pro = mean(as.numeric(YearsCodePro), na.rm = TRUE))\n\n\nWarning: There were 35 warnings in `summarize()`.\nThe first warning was:\nℹ In argument: `avg_years_code_pro = mean(as.numeric(YearsCodePro), na.rm =\n  TRUE)`.\nℹ In group 1: `DevType = \"Academic researcher\"`.\nCaused by warning in `mean()`:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 34 remaining warnings.\n\n\nCode\navg_years_code_pro &lt;- avg_years_code_pro %&gt;%\n  mutate(DevType = fct_explicit_na(DevType, na_level = \"NA\")) %&gt;%\n  mutate(DevType = fct_rev(DevType))  # Reverse factor levels\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `DevType = fct_explicit_na(DevType, na_level = \"NA\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\n\nCode\n# Create the Cleveland dot plot\nggplot(avg_years_code_pro, aes(x = avg_years_code_pro, y = reorder(DevType, avg_years_code_pro))) +\n  geom_point(color = \"skyblue\", size = 2) +  # Use points instead of bars\n  labs(x = \"Average Years of Professional Coding\", y = \"Developer Type\", \n       title = \"Average Years of Professional Coding by Developer Type\") +\n  theme_minimal() +  # Cleaner theme\n  theme(axis.text.y = element_text(size = 10),  # Adjust y-axis text size\n        axis.title = element_text(size = 12))  # Adjust axis title size\n\n\n\n\n\n\n\n\n\nThis graph represents and confirms what is already suspected, those with most years of professional coding experience are at higher positions like C-Suite, Managers, Product Managers whereas those with lower years of coding experience tend to be Students, Data Analysts, Designers etc. Higher Experience Roles: C-Suite Executives oversee company-wide, strategy, budgeting, and long-term planning, responsibilities often gained after years of technical and managerial experience. Product Managers need domain knowledge and business acumen, skills that are developed through years of cross-functional experience.\nLower Experience Roles: These roles often serve as entry-level positions or focus on specific aspects of tech projects without requiring extensive coding experience. Students are just beginning their journey and likely still developing coding expertise through education and internships. Data Analysts often rely more on tools like Excel, SQL, and Tableau rather than programming-heavy workflows, making these roles accessible to those with foundational coding knowledge. Designers focus on user interfaces and experiences, requiring creativity and knowledge of design tools more than coding proficiency.\n\n\nCode\nSOVisitFreq_order &lt;- c('Less than once per month or monthly', 'A few times per month or weekly', 'A few times per week', 'Daily or almost daily', 'Multiple times per day')\nselected$SOVisitFreq &lt;- factor(selected$SOVisitFreq, levels = SOVisitFreq_order, ordered = TRUE)\n\nfiltered_data &lt;- selected |&gt;\n  filter(!is.na(AISelect) & !is.na(SOVisitFreq))\n\ncontingency_table &lt;- table(filtered_data$SOVisitFreq, filtered_data$AISelect)\n\nmosaicplot(contingency_table, color=TRUE, shade=TRUE, las = 1, main='Relationship between using SO and using AI')\n\n\n\n\n\n\n\n\n\n\n\nCode\nrequire(HH)\n\n\nLoading required package: HH\n\n\nLoading required package: lattice\n\n\nLoading required package: grid\n\n\nLoading required package: latticeExtra\n\n\n\nAttaching package: 'latticeExtra'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    layer\n\n\nLoading required package: multcomp\n\n\nLoading required package: mvtnorm\n\n\nLoading required package: survival\n\n\nLoading required package: TH.data\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    survey\n\n\nThe following object is masked from 'package:plotly':\n\n    select\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\n\nLoading required package: gridExtra\n\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\n\nAttaching package: 'HH'\n\n\nThe following object is masked from 'package:lubridate':\n\n    interval\n\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\n\nThe following object is masked from 'package:base':\n\n    is.R\n\n\nCode\nrequire(grid)\nrequire(lattice)\nrequire(latticeExtra)\n\ndf_long &lt;- selected %&gt;%\n  pivot_longer(cols = starts_with(\"Knowledge_\"),\n               names_to = \"Question\",\n               values_to = \"Response\")\n\ndf_counts &lt;- df_long %&gt;%\n  count(Question, Response) %&gt;%\n  pivot_wider(names_from = Response, values_from = n, values_fill = list(n = 0))\n\nlikert(Question ~ .,data=df_counts, ylab=NULL, ReferenceZero=3,\n  as.percent=TRUE,\n  main = list(\"Team-Related Questions\",x=unit(.55, \"npc\")),\n   xlim=c(-40,-20,0,20,40,60,80,100), strip=FALSE,\n   par.strip.text=list(cex=.7))\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(viridis)\n\n\nLoading required package: viridisLite\n\n\nCode\nlibrary(plotly)\n\nAI_survey &lt;- read.csv('data/parsed_AItools.csv')\nAI &lt;- subset(AI_survey, select = -X)\n\ndata_long &lt;- AI %&gt;%\n  pivot_longer(cols = -index, names_to = \"category\", values_to = \"value\")\n\nggplot(data_long, aes(x = index, y = category, fill = value)) +\n  geom_tile() +\n  scale_fill_viridis(option = \"C\") +  # Color scale\n  labs(x = \"Development Workflow\", y = \"AI integration interest\", title = \"Interest in Integrating AI into Development Activities\") +\n  scale_y_discrete(labels = c(\"Currently.Using\" = \"Currently using\", \"Interested.in.Using\" = \"Interested in using\", \"Not.interested.in.Using\" = \"Not interested in using\")) +  # Relabel y-axis\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(selected, aes(x = AISelect, y = Age)) +\n  geom_jitter(aes(color = AISelect), width = 0.1, height = 0.1, alpha = 0.05) +\n  theme_minimal() +\n  labs(title = \"Jitter Plot of AISelect vs Age\",\n       x = \"AISelect\",\n       y = \"Age\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(selected, aes(x = DevType, fill = RemoteWork)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Developer Type\", y = \"Proportion of Remote Work\", \n       title = \"Proportion of Remote Work by Developer Type\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nRoles such as Data Scientist or Machine Learning Specialist, Cloud Infrastructure Engineer, and Developer - Backend have significant proportions of employees working fully remote, indicating these roles are well-suited for remote work environments. Hybrid work is the most common mode for many roles, such as Product Manager, Full-stack Developer, and Site Reliability Engineer, indicating a balanced approach where both remote and in-person presence are valued. In-person work is seen more in roles like Hardware Engineer, Engineering Manager, and System Administrator, which may require physical presence due to the nature of their responsibilities, such as managing physical systems or hardware.\n\n\nCode\nggplot(selected, aes(x = as.factor(AISelect), y = as.numeric(JobSat))) +\n  geom_jitter(aes(), alpha = 0.1, width = 0.2) +  # Add jitter for better visibility\n  labs(x = \"AI Tool Selection\", y = \"Job Satisfaction\",\n       title = \"AI Tool Usage vs Job Satisfaction by Stack overflow visit freq\") +\n  facet_wrap(~ SOVisitFreq) +  # Facet by RemoteWork status\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\nWarning: Removed 36311 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nIndividuals who selected Yes for AI tool usage generally show high job satisfaction across all visit frequencies. Those planning to use AI tools soon seem to have slightly lower job satisfaction compared to current users but higher satisfaction than those not using AI tools. Job satisfaction appears distributed similarly across different Stack Overflow visit frequencies. Frequent visitors exhibit a larger spread of job satisfaction, potentially indicating diverse user experiences. Denser areas in each plot indicate where most responses are concentrated. “Yes” under AI Tool Selection has a higher density at the top of the y-axis, suggesting a positive association between AI tool usage and job satisfaction. This analysis suggests that using AI tools is associated with higher job satisfaction, regardless of Stack Overflow visit frequency.\n\n\nCode\nggplot(selected, aes(x = SOPartFreq, fill = RemoteWork)) +\n  geom_bar(position = \"dodge\", color = \"black\") +\n  labs(x = \"Participation Frequency\", \n       y = \"Count\", \n       fill = \"Remote Work Setup\",\n       title = \"Participation Frequency vs. Remote Work Setup\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nThe Hybrid (some remote, some in-person) setup is the most frequent across all participation categories. In-person workers generally participate less frequently, with lower counts in all categories except for “Less than once per month or monthly.” The Remote group has a significant number of participants, particularly in the “Multiple times per day” and “Daily or almost daily” categories, but still lower than the Hybrid group. “A few times per week” and “Less than once per month or monthly” show low levels of participation, especially in the In-person group, indicating less frequent participation in Stack Overflow for those working primarily in-person. The “I have never participated in Q&A on Stack Overflow” category shows a notable number of In-person workers, suggesting lower engagement from those not working remotely.\n\n\nCode\nselected_vf_pf &lt;- selected %&gt;%\n  filter(!is.na(SOVisitFreq) & !is.na(SOPartFreq))\n\n# Create the plot\nggplot(selected_vf_pf, aes(x = SOVisitFreq, fill = SOPartFreq)) +\n  geom_bar(position = \"fill\", color = \"black\") +\n  labs(x = \"Visit Frequency\", \n       y = \"Proportion\", \n       fill = \"Participation Frequency\",\n       title = \"Relationship Between Visit and Participation Frequency\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nFor those visiting “Once per month or monthly,” a significant portion has never participated, or participates less than once per month. This suggests that infrequent visitors are less likely to engage actively. As visit frequency increases to “A few times per month or weekly,” there is a noticeable increase in participation, particularly in the “A few times per week” category. This indicates that more frequent visits are associated with higher engagement. For those visiting “Daily or almost daily,” participation is more evenly distributed across different frequencies, with a notable increase in daily participation. The category “Multiple times per day” shows a high level of active participation, with many users participating multiple times daily. The proportion of users who have never participated decreases as visit frequency increases. Users visiting more frequently tend to participate more actively. This is evident from the increasing proportions in categories like “Daily or almost daily” and “Multiple times per day” as visit frequency increases.\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Prepare data: Count frequency of combinations of AIThreat and AISent\nai_threat_sentiment &lt;- selected %&gt;%\n  filter(!is.na(AIThreat) & !is.na(AISent)) %&gt;%\n  count(AIThreat, AISent)\n\n# Create a stacked bar plot\nggplot(ai_threat_sentiment, aes(x = AISent, y = n, fill = AIThreat)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"AI Threat Perception vs AI Sentiment\",\n       x = \"AI Sentiment\",\n       y = \"Count\",\n       fill = \"AI Threat\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(viridis)\nlibrary(maps)\n\n\n\nAttaching package: 'maps'\n\n\nThe following object is masked from 'package:viridis':\n\n    unemp\n\n\nThe following object is masked from 'package:purrr':\n\n    map\n\n\nCode\n# Assume 'selected' is the dataset you're working with\n\n# Step 1: Summarize the average Job Satisfaction by country\njob_sat_data &lt;- selected %&gt;%\n  filter(!is.na(JobSat)) %&gt;%  # Remove rows with missing job satisfaction data\n  group_by(Country) %&gt;%  # Group by country\n  summarise(AvgJobSat = mean(as.numeric(as.character(JobSat)), na.rm = TRUE))  # Calculate average job satisfaction\n\n# Step 2: Get map data\nmap_data &lt;- map_data(\"world\")\n\n# Step 3: Merge the map data with the summarized job satisfaction data\nmerged_data &lt;- left_join(map_data, job_sat_data, by = c(\"region\" = \"Country\"))\n\n# Step 4: Plot the choropleth map\nggplot(merged_data, aes(x = long, y = lat, group = group, fill = AvgJobSat)) +\n  geom_polygon(color = \"black\", size = 0.1) +  # Draw polygons with black borders\n  scale_fill_viridis(option = \"magma\", direction = -1, name = \"Avg Job Sat\") +  # Use 'viridis' color scale for better visibility\n  theme_void() +  # Remove axis and grid lines for a cleaner map\n  labs(title = \"Average Job Satisfaction by Country\")  # Add title\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(viridis)\nlibrary(maps)\n\n# Step 1: Summarize the proportion of people who think AI is a threat by country\nai_threat_data &lt;- selected %&gt;%\n  filter(!is.na(AIThreat)) %&gt;%  # Remove rows with missing data\n  group_by(Country) %&gt;%  # Group by country\n  summarise(\n    ThreatCount = sum(AIThreat == \"Yes\", na.rm = TRUE),  # Count how many think AI is a threat\n    TotalCount = n(),  # Count the total number of responses\n    ProportionThreat = ThreatCount / TotalCount * 100  # Calculate the proportion\n  )\n\n# Step 2: Get map data\nmap_data &lt;- map_data(\"world\")\n\n# Step 3: Merge the map data with the summarized AI threat data\nmerged_data &lt;- left_join(map_data, ai_threat_data, by = c(\"region\" = \"Country\"))\n\n# Step 4: Plot the choropleth map\nggplot(merged_data, aes(x = long, y = lat, group = group, fill = ProportionThreat)) +\n  geom_polygon(color = \"black\", size = 0.1) +  # Draw polygons with black borders\n  scale_fill_viridis(option = \"magma\", direction = -1, name = \"AI Threat Proportion (%)\") +  # Use 'viridis' color scale\n  theme_void() +  # Remove axis and grid lines for a cleaner map\n  labs(title = \"Proportion of People Who Think AI is a Threat by Country\")  # Add title\n\n\n\n\n\n\n\n\n\n\n\nCode\nai_next &lt;- read.csv('data/ai_next.csv')\n\nlikert(index ~ .,data=ai_next, ylab=NULL, ReferenceZero=3,\n  as.percent=TRUE,\n  main = list(\"Future AI integration into workflow\",x=unit(.55, \"npc\")),\n  strip=FALSE,\n   par.strip.text=list(cex=.7))\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\n\n# Define the correct order of education levels\nselected$EdLevel &lt;- factor(selected$EdLevel, \n                           levels = c(\"Primary/elementary school\", \n                                      \"Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)\",\n                                      \"Some college/university study without earning a degree\",\n                                      \"Associate degree (A.A., A.S., etc.)\",\n                                      \"Bachelor’s degree (B.A., B.S., B.Eng., etc.)\",\n                                      \"Master’s degree (M.A., M.S., M.Eng., MBA, etc.)\",\n                                      \"Professional degree (JD, MD, Ph.D, Ed.D, etc.)\",\n                                      \"Something else\"))\n\n\nggplot(selected, aes(x = EdLevel)) +\n  geom_bar(fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Distribution of Highest Level of Formal Education\",\n    x = \"Education Level\",\n    y = \"Count\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nFrom this graph it can be seen that the most common highest qualification for people is a Bachelor’s degree, followed by a Master’s degree. Over 40,000 individuals have achieved higher education degrees (Bachelor’s, Master’s, and Professional degrees). This suggests a strong focus on advanced education within the community. Approximately 16,000+ individuals fall into categories such as pre-primary, secondary, some college without a degree, associate degrees, and “something else.” This indicates that fewer people stop their formal education at these levels. The substantial number of Master’s and Professional degrees signifies a trend toward pursuing advanced education.\n\n\nCode\n# Install and load treemap package\nlibrary(treemap)\n\n# Create a treemap for education levels\nindustry_counts_df &lt;- as.data.frame(table(selected$Industry))\n\n# Create the treemap with labels and legend\ntreemap(industry_counts_df,\n        index = \"Var1\",  # Category variable\n        vSize = \"Freq\",  # Size based on frequency\n        vColor = \"Freq\", # Color based on frequency\n        palette = \"Blues\", # Customize the color palette\n        draw = TRUE,\n        title = \"Distribution of Industries of Respondents\",\n        fontsize.title = 16,  # Adjust title font size\n        fontsize.labels = 12, # Adjust labels font size\n        fontsize.legend = 10, # Adjust legend font size\n        legend = TRUE,  # Show legend\n        border.col = \"white\" # White border around the tiles for better visibility\n)\n\n\n\n\n\n\n\n\n\nSoftware Development is the largest sector, occupying a significant portion of the distribution. This could reflect the high engagement of software developers in surveys like these. Fintech and Internet, Telecomm or Information Services are also prominent, reflecting the growing importance of digital financial services and communication technologies. Healthcare and Retail and Consumer Services are moderately sized. Sectors like Banking/Financial Services, Manufacturing, and Government have smaller representations, suggesting either niche markets or less emphasis compared to larger sectors. Media & Advertising Services, Higher Education, and Transportation, or Supply Chain are similarly sized. The inclusion of non-tech industries like Healthcare, Government, and Retail shows that technology professionals are present across diverse fields. The dominance of tech industries highlights the survey’s appeal to respondents working in these domains.\n\n\nCode\nggplot(selected, aes(x = Age)) +\n  geom_bar(fill='lightblue') +\n  facet_wrap(~ MainBranch) +\n  theme_minimal() +\n  labs(title = \"Distribution of Age by Main Branch\",\n       x = \"Age\",\n       y = \"Count\")+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nThe majority of respondents are professional developers, particularly in the 18-24 and 25-34 age groups. This indicates a strong presence of young professionals in the tech industry. Those who code primarily as a hobby or are learning to code are significantly fewer compared to professional developers. However, they are present across all age groups, with a slight concentration in younger demographics. Individuals who used to be developers but no longer are form a very small portion of the sample, suggesting that career transitions out of development might be less common or that they move into roles still related to technology. People who code as part of their work or studies but not as their primary role are spread across various age groups, with notable numbers in the 25-34 and 35-44 age ranges. This reflects the interdisciplinary nature of coding skills in various professions. The 18-24 and 25-34 age groups dominate across most categories, highlighting these as key ages for both entering and establishing a career in coding.\n\n\nCode\nindustry_summary &lt;- selected |&gt;\n  dplyr::group_by(Industry) |&gt;\n  dplyr::summarize(Count = dplyr::n(), .groups = \"drop\")\n\n# Preview the dataset\nprint(industry_summary)\n\n\n# A tibble: 16 × 2\n   Industry                                   Count\n   &lt;chr&gt;                                      &lt;int&gt;\n 1 Banking/Financial Services                  1371\n 2 Computer Systems Design and Services         844\n 3 Energy                                       578\n 4 Fintech                                     1641\n 5 Government                                   962\n 6 Healthcare                                  1277\n 7 Higher Education                             890\n 8 Insurance                                    389\n 9 Internet, Telecomm or Information Services  1629\n10 Manufacturing                               1265\n11 Media & Advertising Services                 894\n12 Other:                                      3077\n13 Retail and Consumer Services                1264\n14 Software Development                       11918\n15 Transportation, or Supply Chain              859\n16 &lt;NA&gt;                                       36579\n\n\nCode\n# Export to a CSV file\nwrite.csv(industry_summary, \"data/industry_summary.csv\", row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  }
]