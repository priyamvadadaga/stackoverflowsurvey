[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "StackOverflow 2024 Survey Analysis",
    "section": "",
    "text": "1 Introduction\nBefore OpenAI and other LLMs were built, StackOverflow was the go-to source for developers to have their questions answered. In May 2024 over 65,000 developers responded to Stack Overflow’s annual survey about coding, working, AI and how they feel about the industry. This data can provide valuable insights into the current state of the tech industry. As individuals who work in tech or aim to work in tech, understanding these trends is both interesting and essential These insights are crucial for understanding how the industry is evolving and how developers feel about the tools, skills, and environments shaping their work.\nQuestions we’re interested in:\n\nDemographics of respondents: to understand the landscape of users StackOverflow caters to\nPerspectives on AI: to understand developers’ views on AI in the workplace, especially in the world of generative AI as a threat to certain jobs\nStackOverflow usage: With the advent of GPT, LLama and other LLM’s, how developers’ perspectives on more “traditional” sources like StackOverflow are changing and whether it still adequately meets their needs.\n\n(As we explore the data further and discover patterns, we will refine and update our research questions.)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nThis is the link from which the data set has been obtained: Stack Overflow Survey 2024\nEvery May since 2011, Stack Overflow conducts an annual survey. The 2024 survey included data about coding, working, AI and Stack Overflow users’ profiles and perceptions in these domains. The data is collected by Stack Overflow via a Qualtrics survey, and is updated on a yearly basis. The survey follows a questionnaire style with different types of questions including single-choice, multi-select, and Likert scale questions, ranking scale, boolean and text-based.\nThe May 2024 survey had over 65,000 respondents. Stack Overflow publishes results as a data table with 114 features (engineered from 87 questions) and 65,437 rows. It additionally publishes a schema and the questionnaire itself.\nOne concern in terms of parsing is with regards to multi-select questions. Parsing these either result in adding multiple columns which will have many missing values or parsing them in all possible combinations which has little interpretability. Hence, to begin, we limit the inputs to our analysis to the other question types. Additionally, we went through the schema and have picked questions whose responses are relevant to our research questions.\nFinally, the data is downloaded into the ‘data’ folder and is imported using read.csv in R.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(dplyr)\n\nsurvey &lt;- read.csv('data/survey_results_public.csv')\nschema &lt;- read.csv('data/survey_results_schema.csv')\n\n# ncol(survey)\n# nrow(survey)\n\nkeep &lt;- c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'YearsCode', 'YearsCodePro', 'DevType', 'Country', 'ConvertedCompYearly', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'WorkExp', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'Industry', 'JobSat', 'SurveyLength', 'SurveyEase')\n\n\nselected &lt;- survey |&gt; dplyr::select(all_of(keep))\n\n# colSums(is.na(selected))\n# colMeans(is.na(selected)) * 100\n\nselected &lt;- selected |&gt;\n  mutate(across(c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'DevType', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'JobSat', 'SurveyLength', 'SurveyEase'), as.factor))\n\n\n\n\nCode\nlibrary(ggplot2)\nmissing_counts &lt;- colSums(is.na(selected))\nmissing_percent &lt;- (missing_counts / nrow(selected)) * 100\nmissing_df &lt;- data.frame(\n  column = names(missing_counts),\n  missing_percent = missing_percent\n)\nmissing_df$column &lt;- factor(missing_df$column, levels = missing_df$column)\n\nggplot(missing_df, aes(x = column, y = missing_percent)) +\n  geom_bar(stat = \"identity\", fill='skyblue') +\n  labs(\n    title = \"Percentage of Missing Values per Column\",\n    x = \"Columns\",\n    y = \"Missing Values (%)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size=8)) +\n  scale_y_continuous(limits = c(0, 100))\n\n\n\n\n\n\n\n\n\nWe first look at the percentage of missing values in each of our selected columns. As is expected from an online questionnaire, there is a very high number of missing values with multiple columns crossing the 50% threshold as well. We observe that the ‘Check’ column, which was just a check to ensure that the participant was paying attention to the survey has zero missing values. Thus, we do not eliminate any rows based on this check. We also notice that the series of ‘Knowledge_’ questions, which all serve as part of a Likert-scale question have high missing values. These are probably a result of people skipping the question entirely.\nTo further check if there are any correlations between not answering certain types of questions, we plot a heatmap of correlations between missing values. We cannot compute correlations for Age, Check, and MainBranch since these questions have have no missing values.\n\n\nCode\nlibrary(reshape2)\n\n\n\nAttaching package: 'reshape2'\n\n\nThe following object is masked from 'package:tidyr':\n\n    smiths\n\n\nCode\nmissing_matrix &lt;- is.na(selected) * 1\nmissing_corr &lt;- cor(missing_matrix)\n\n\nWarning in cor(missing_matrix): the standard deviation is zero\n\n\nCode\nmissing_corr_melted &lt;- melt(missing_corr)\n\nggplot(missing_corr_melted, aes(Var1, Var2, fill = value)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient2(\n    low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0,\n    limit = c(-1, 1), space = \"Lab\", name = \"Correlation\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size=6),\n    axis.text.y = element_text(size=6)\n  ) +\n  labs(title = \"Correlation of Missing Values\", x = \"Columns\", y = \"Columns\")\n\n\n\n\n\n\n\n\n\nWe observe that, typically, blocks of questions have missing values. For instance, it seems that missing values are correlated in the professional-related questions, i.e. from the column ICorPM until the industry question. These are perhaps a result of the individual being a student or just a hobby-developer. Similarly, another block of correlation is observed for the AI-related questions. Thus, it seems that perhaps, when skipping, individuals skipped certain lines of questioning entirely.\nWe believe that we can retain value by keeping these rows with missing values since perhaps the missing values form clusters of individuals. We explore one other cause of missing values - fatigue. To check this, we plot the percent missing values over the questions in order that they were answered, faceted on their answer to one of the last questions – “How do you feel about the length of the survey this year?”\n\n\nCode\nselected$SurveyLength &lt;- fct_na_value_to_level(selected$SurveyLength)\n\nmissing_values &lt;- selected %&gt;%\n  group_by(SurveyLength) %&gt;%\n  summarise(across(everything(), ~ mean(is.na(.)))) %&gt;%\n  pivot_longer(cols = -SurveyLength, names_to = \"question\", values_to = \"missing_proportion\")\n\nmissing_values &lt;- missing_values %&gt;%\n  left_join(schema, by = c(\"question\" = \"qname\"))\n\nggplot(missing_values, aes(x = question, y = missing_proportion)) +\n  geom_line(group = 1, color = \"darkgrey\", size = 0.5) +\n  geom_point(aes(color = force_resp), size = 1.5) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = -0.01, size = 6)) +\n  labs(x = \"Survey Question\", y = \"Proportion of Missing Values\",\n       title = \"Missing Data Across Survey Questions by SurveyLength\",\n       color = \"Required Question\") +\n  facet_wrap(~ SurveyLength)\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nWe notice, as a general pattern, that the missing values have a somewhat upward trend as users progressed in the survey. As expected, the highest likelihood of missing values is when the last question is unanswered. Interestingly, those that thought the survey was “Too Short” had a higher proportion of missing values compared to those that thought it was “Too long”. Although somewhat counter intuitive, perhaps it is the fatigue from actually answering the questions that results in answering “Too long”, while not answering leads to believing it was too short.\nWe additionally look at data on whether the question is a required question. We notice that certain non-required questions also have very few missing values, indicating user keenness on answering these questions, such as their current development type (i.e. job) and questions regarding their experience with Stack Overflow. We also notice how even certain required questions have high missing values, which perhaps indicates a systemic flaw. We are considering dropping the rows where a required question was not answered, since this likely indicates an incomplete survey that was wrongly submitted.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(dplyr)\n\nsurvey &lt;- read.csv('data/survey_results_public.csv')\nschema &lt;- read.csv('data/survey_results_schema.csv')\n\n# ncol(survey)\n# nrow(survey)\n\nkeep &lt;- c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'YearsCode', 'YearsCodePro', 'DevType', 'Country', 'ConvertedCompYearly', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'WorkExp', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'Industry', 'JobSat', 'SurveyLength', 'SurveyEase')\n\n\nselected &lt;- survey |&gt; dplyr::select(all_of(keep))\n\n# colSums(is.na(selected))\n# colMeans(is.na(selected)) * 100\n\nselected &lt;- selected |&gt;\n  mutate(across(c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'DevType', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'JobSat', 'SurveyLength', 'SurveyEase'), as.factor))\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(ggalluvial)\nlibrary(dplyr)\n\nAIThreat_order &lt;- c('No', 'Unsure', 'Yes')\nselected$AIThreat &lt;- factor(selected$AIThreat, levels = AIThreat_order, ordered = TRUE)\n\nAISent_order &lt;- c('Unsure', 'Very unfavorable', 'Unfavorable', 'Indifferent', 'Favorable', 'Very favorable')\nselected$AISent &lt;- factor(selected$AISent, levels = AISent_order, ordered = TRUE)\n\nAIComplex_order &lt;- c('Very poor at handling complex tasks', 'Bad at handling complex tasks', 'Neither good or bad at handling complex tasks', 'Good, but not great at handling complex tasks', 'Very well at handling complex tasks')\nselected$AIComplex &lt;- factor(selected$AIComplex, levels = AIComplex_order, ordered = TRUE)\n\nAIAcc_order &lt;- c('Highly distrust', 'Somewhat distrust', 'Neither trust nor distrust', 'Somewhat trust', 'Highly trust')\nselected$AIAcc &lt;- factor(selected$AIAcc, levels = AIAcc_order, ordered = TRUE)\n\n# Clean data to remove rows with NA values\nfiltered_data &lt;- selected %&gt;%\n  filter(MainBranch == \"I am a developer by profession\") %&gt;%\n  filter(!is.na(AISelect) & !is.na(AISent) & !is.na(AIAcc) & !is.na(AIComplex) & !is.na(AIThreat))\n\n\n\n\nCode\nggplot(filtered_data,\n       aes(axis1 = AIThreat, axis2 = AIComplex, axis3 = AISent, axis4 = AIAcc)) +\n  geom_alluvium(aes(fill = AIAcc)) +\n  geom_stratum(aes(fill = AIAcc), color = \"black\", size = 0.5) +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum)), size = 2.5, color = \"black\") +\n  scale_x_discrete(limits = c(\"AIThreat\", \"AIComplex\", \"AISent\", \"AIAcc\"),\n                   expand = c(0.15, 0.15)) +\n  scale_fill_brewer(palette = \"RdYlBu\") +\n  theme_void() +\n  theme(\n    strip.text = element_text(size = 10),\n    axis.text = element_text(size = 8),\n    axis.title = element_text(size = 10),\n    plot.title = element_text(size = 14)\n  ) +\n  ggtitle(\"Alluvial Diagram for Developers\")\n\n\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\n\n\nWarning: Computation failed in `stat_stratum()`.\nCaused by error in `switch()`:\n! EXPR must be a length 1 vector\n\n\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(forcats)\n\n# Reorder DevType and place NA at the bottom\navg_years_code_pro &lt;- selected %&gt;%\n  group_by(DevType) %&gt;%\n  summarize(avg_years_code_pro = mean(as.numeric(YearsCodePro), na.rm = TRUE))\n\n\nWarning: There were 35 warnings in `summarize()`.\nThe first warning was:\nℹ In argument: `avg_years_code_pro = mean(as.numeric(YearsCodePro), na.rm =\n  TRUE)`.\nℹ In group 1: `DevType = \"Academic researcher\"`.\nCaused by warning in `mean()`:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 34 remaining warnings.\n\n\nCode\navg_years_code_pro &lt;- avg_years_code_pro %&gt;%\n  mutate(DevType = fct_explicit_na(DevType, na_level = \"NA\")) %&gt;%\n  mutate(DevType = fct_rev(DevType))  # Reverse factor levels\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `DevType = fct_explicit_na(DevType, na_level = \"NA\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\n\nCode\n# Create the Cleveland dot plot\nggplot(avg_years_code_pro, aes(x = avg_years_code_pro, y = reorder(DevType, avg_years_code_pro))) +\n  geom_point(color = \"skyblue\", size = 2) +  # Use points instead of bars\n  labs(x = \"Average Years of Professional Coding\", y = \"Developer Type\", \n       title = \"Average Years of Professional Coding by Developer Type\") +\n  theme_minimal() +  # Cleaner theme\n  theme(axis.text.y = element_text(size = 10),  # Adjust y-axis text size\n        axis.title = element_text(size = 12))  # Adjust axis title size\n\n\n\n\n\n\n\n\n\n\n\nCode\nSOVisitFreq_order &lt;- c('Less than once per month or monthly', 'A few times per month or weekly', 'A few times per week', 'Daily or almost daily', 'Multiple times per day')\nselected$SOVisitFreq &lt;- factor(selected$SOVisitFreq, levels = SOVisitFreq_order, ordered = TRUE)\n\nfiltered_data &lt;- selected |&gt;\n  filter(!is.na(AISelect) & !is.na(SOVisitFreq))\n\ncontingency_table &lt;- table(filtered_data$SOVisitFreq, filtered_data$AISelect)\n\nmosaicplot(contingency_table, color=TRUE, shade=TRUE, las = 1)\n\n\n\n\n\n\n\n\n\n\n\nCode\nrequire(HH)\n\n\nLoading required package: HH\n\n\nLoading required package: lattice\n\n\nLoading required package: grid\n\n\nLoading required package: latticeExtra\n\n\n\nAttaching package: 'latticeExtra'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    layer\n\n\nLoading required package: multcomp\n\n\nLoading required package: mvtnorm\n\n\nLoading required package: survival\n\n\nLoading required package: TH.data\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    survey\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\n\nLoading required package: gridExtra\n\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\n\nAttaching package: 'HH'\n\n\nThe following object is masked from 'package:lubridate':\n\n    interval\n\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\n\nThe following object is masked from 'package:base':\n\n    is.R\n\n\nCode\nrequire(grid)\nrequire(lattice)\nrequire(latticeExtra)\n\ndf_long &lt;- selected %&gt;%\n  pivot_longer(cols = starts_with(\"Knowledge_\"),\n               names_to = \"Question\",\n               values_to = \"Response\")\n\ndf_counts &lt;- df_long %&gt;%\n  count(Question, Response) %&gt;%\n  pivot_wider(names_from = Response, values_from = n, values_fill = list(n = 0))\n\nlikert(Question ~ .,data=df_counts, ylab=NULL, ReferenceZero=3,\n  as.percent=TRUE,\n  main = list(\"Team-Related Questions\",x=unit(.55, \"npc\")),\n   xlim=c(-40,-20,0,20,40,60,80,100), strip=FALSE,\n   par.strip.text=list(cex=.7))\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(viridis)\n\n\nWarning: package 'viridis' was built under R version 4.4.2\n\n\nLoading required package: viridisLite\n\n\nCode\nlibrary(plotly)\n\n\nWarning: package 'plotly' was built under R version 4.4.2\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:MASS':\n\n    select\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n\nCode\nAI_survey &lt;- read.csv('data/parsed_AItools.csv')\nAI &lt;- subset(AI_survey, select = -X)\n\ndata_long &lt;- AI %&gt;%\n  pivot_longer(cols = -index, names_to = \"category\", values_to = \"value\")\n\ndata_long\n\n\n# A tibble: 33 × 3\n   index                     category                value\n   &lt;chr&gt;                     &lt;chr&gt;                   &lt;int&gt;\n 1 Learning about a codebase Currently.Using         11105\n 2 Learning about a codebase Interested.in.Using     14599\n 3 Learning about a codebase Not.interested.in.Using  6742\n 4 Project planning          Currently.Using          4381\n 5 Project planning          Interested.in.Using     11407\n 6 Project planning          Not.interested.in.Using 15225\n 7 Writing code              Currently.Using         29486\n 8 Writing code              Interested.in.Using      3296\n 9 Writing code              Not.interested.in.Using  2106\n10 Documenting code          Currently.Using         14439\n# ℹ 23 more rows\n\n\nCode\nggplot(data_long, aes(x = index, y = value, fill = category)) +\n    geom_bar(stat = \"identity\", position = \"fill\") +  # Use \"fill\" for proportions\n  labs(x = \"Activity\", y = \"Count\", title = \"Which parts of your development workflow are you currently using AI tools for\\nand which are you interested in using AI tools for over the next year?\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_long, aes(x = index, y = category, fill = value)) +\n  geom_tile() +\n  scale_fill_viridis(option = \"C\") +  # Color scale\n  labs(x = \"Activity\", y = \"Category\", title = \"Heatmap of Interest in Development Activities\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data_long, aes(x = index, y = value, color = category)) +\n  geom_point(position = position_jitter(width = 0.1, height = 0), size = 3) +\n  labs(x = \"Activity\", y = \"Count\", title = \"Dot Plot of Interest in Development Activities\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_color_manual(values = c(\"Currently_Using\" = \"blue\", \n                               \"Interested_in_Using\" = \"orange\", \n                               \"Not_interested_in_Using\" = \"gray\"))\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\n\n\n\n\n\n\n\nCode\nplot_ly(data_long, x = ~index, y = ~value, color = ~category, type = 'bar', \n        text = ~paste(\"Count: \", value), hoverinfo = 'text') %&gt;%\n  layout(\n    title = \"Interest in Different Development Activities\",\n    xaxis = list(title = \"Activity\"),\n    yaxis = list(title = \"Count\"),\n    barmode = \"dodge\"\n  )\n\n\n\n\n\n\n\n\nCode\nggplot(selected, aes(x = AISelect, y = Age)) +\n  geom_jitter(aes(color = AISelect), width = 0.1, height = 0.1, alpha = 0.05) +\n  theme_minimal() +\n  labs(title = \"Jitter Plot of AISelect vs Age\",\n       x = \"AISelect\",\n       y = \"Age\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Load necessary libraries\nlibrary(ggplot2)\n\ndf_summary &lt;- as.data.frame(table(selected$AISelect, selected$Age))\n\nggplot(df_summary, aes(x = Var1, y = Var2, fill=)) +\n  geom_tile() +\n  scale_fill_viridis_c() +  # Use a color scale to show density\n  theme_minimal() +\n  labs(title = \"Heatmap of Counts for AISelect and Age\",\n       x = \"AISelect\",\n       y = \"Age\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(selected, aes(x = DevType, fill = RemoteWork)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Developer Type\", y = \"Proportion of Remote Work\", \n       title = \"Proportion of Remote Work by Developer Type\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(selected %&gt;% filter(!is.na(RemoteWork)), aes(x = as.factor(AISelect), y = as.numeric(JobSat))) +\n  geom_jitter(aes(), alpha = 0.1, width = 0.2) +  # Add jitter for better visibility\n  labs(x = \"AI Tool Selection\", y = \"Job Satisfaction\",\n       title = \"AI Tool Usage vs Job Satisfaction by Age\") +\n  facet_wrap(~ Age) +  # Facet by RemoteWork status\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\nWarning: Removed 25689 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(selected, aes(x = as.factor(AISelect), y = as.numeric(JobSat))) +\n  geom_jitter(aes(), alpha = 0.1, width = 0.2) +  # Add jitter for better visibility\n  labs(x = \"AI Tool Selection\", y = \"Job Satisfaction\",\n       title = \"AI Tool Usage vs Job Satisfaction by Age\") +\n  facet_wrap(~ SOVisitFreq) +  # Facet by RemoteWork status\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\nWarning: Removed 36311 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(selected, aes(x = AISelect, y = as.numeric(JobSat), fill = AISelect)) +\n  geom_boxplot(alpha = 0.6) +\n  labs(x = \"AI Tool Selection\", y = \"Job Satisfaction\", \n       title = \"Job Satisfaction by AI Tool Selection\") +\n  facet_wrap(~ RemoteWork) +  # Facet by RemoteWork\n  scale_fill_manual(values = c(\"lightblue\", \"lightgreen\", \"lightcoral\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\nWarning: Removed 36311 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Categorize JobSat into 3 levels\nselected &lt;- selected %&gt;%\n  mutate(JobSat_Grouped = case_when(\n    as.numeric(as.character(JobSat)) &gt;= 0 & as.numeric(as.character(JobSat)) &lt;= 3 ~ \"Low\",\n    as.numeric(as.character(JobSat)) &gt;= 4 & as.numeric(as.character(JobSat)) &lt;= 7 ~ \"Medium\",\n    as.numeric(as.character(JobSat)) &gt;= 8 & as.numeric(as.character(JobSat)) &lt;= 10 ~ \"High\",\n    TRUE ~ NA_character_ # Keep NA for missing or invalid data\n  ))\n\n# Remove rows with NA in JobSat_Grouped or WorkExp\nselected &lt;- selected %&gt;%\n  filter(!is.na(JobSat_Grouped) & !is.na(WorkExp))\n\n# Create the plot\nggplot(selected, aes(x = WorkExp, fill = JobSat_Grouped)) +\n  geom_density(alpha = 0.6) +\n  labs(x = \"Work Experience (Years)\", y = \"Density\", \n       title = \"Density of Work Experience by Job Satisfaction Categories\") +\n  facet_wrap(~ RemoteWork) +  # Facet by RemoteWork\n  scale_fill_manual(values = c(\"skyblue\", \"lightgreen\", \"lightcoral\"),  # Adjust colors for 3 categories\n                    name = \"Job Satisfaction\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(selected, aes(x = SOPartFreq, fill = RemoteWork)) +\n  geom_bar(position = \"dodge\", color = \"black\") +\n  labs(x = \"Participation Frequency\", \n       y = \"Count\", \n       fill = \"Remote Work Setup\",\n       title = \"Participation Frequency vs. Remote Work Setup\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(selected, aes(x = SOVisitFreq, fill = SOPartFreq)) +\n  geom_bar(position = \"fill\", color = \"black\") +\n  labs(x = \"Visit Frequency\", \n       y = \"Proportion\", \n       fill = \"Participation Frequency\",\n       title = \"Relationship Between Visit and Participation Frequency\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\nstr(selected)\n\n\n'data.frame':   28979 obs. of  39 variables:\n $ MainBranch          : Factor w/ 5 levels \"I am a developer by profession\",..: 5 1 1 1 3 1 1 1 1 1 ...\n $ Age                 : Factor w/ 8 levels \"18-24 years old\",..: 3 3 4 2 2 4 3 3 2 2 ...\n $ RemoteWork          : Factor w/ 3 levels \"Hybrid (some remote, some in-person)\",..: 3 1 1 1 1 3 3 3 3 1 ...\n $ Check               : Factor w/ 1 level \"Apples\": 1 1 1 1 1 1 1 1 1 1 ...\n $ EdLevel             : Factor w/ 8 levels \"Associate degree (A.A., A.S., etc.)\",..: 2 2 7 7 3 2 2 2 5 2 ...\n $ YearsCode           : chr  \"20\" \"20\" \"31\" \"12\" ...\n $ YearsCodePro        : chr  NA \"12\" \"27\" \"10\" ...\n $ DevType             : Factor w/ 34 levels \"Academic researcher\",..: 28 12 16 16 26 12 16 16 3 26 ...\n $ Country             : chr  \"United States of America\" \"United States of America\" \"Switzerland\" \"Germany\" ...\n $ ConvertedCompYearly : int  NA NA NA NA NA NA NA NA NA NA ...\n $ SOVisitFreq         : Ord.factor w/ 5 levels \"Less than once per month or monthly\"&lt;..: 3 5 2 4 2 2 3 3 5 5 ...\n $ SOAccount           : Factor w/ 3 levels \"No\",\"Not sure/can't remember\",..: 3 3 3 3 3 3 3 3 3 1 ...\n $ SOPartFreq          : Factor w/ 6 levels \"A few times per month or weekly\",..: 5 2 1 2 5 4 5 2 3 NA ...\n $ SOComm              : Factor w/ 6 levels \"Neutral\",\"No, not at all\",..: 5 5 6 5 6 3 3 6 5 6 ...\n $ AISelect            : Factor w/ 3 levels \"No, and I don't plan to\",..: 3 1 1 3 3 3 1 3 3 2 ...\n $ AISent              : Ord.factor w/ 6 levels \"Unsure\"&lt;\"Very unfavorable\"&lt;..: 5 NA NA 6 1 6 NA 5 6 4 ...\n $ AIAcc               : Ord.factor w/ 5 levels \"Highly distrust\"&lt;..: 2 NA NA 3 4 4 NA 3 4 NA ...\n $ AIComplex           : Ord.factor w/ 5 levels \"Very poor at handling complex tasks\"&lt;..: 3 NA NA 3 2 4 NA 4 2 NA ...\n $ AIThreat            : Ord.factor w/ 3 levels \"No\"&lt;\"Unsure\"&lt;..: 1 NA NA 1 NA 1 NA NA 1 1 ...\n $ ICorPM              : Factor w/ 2 levels \"Individual contributor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ WorkExp             : int  15 12 29 12 10 18 16 17 6 7 ...\n $ Knowledge_1         : Factor w/ 5 levels \"Agree\",\"Disagree\",..: 4 4 4 1 4 1 1 1 3 1 ...\n $ Knowledge_2         : Factor w/ 5 levels \"Agree\",\"Disagree\",..: 1 2 3 1 3 2 1 1 1 1 ...\n $ Knowledge_3         : Factor w/ 5 levels \"Agree\",\"Disagree\",..: 4 3 1 3 3 4 1 4 2 2 ...\n $ Knowledge_4         : Factor w/ 5 levels \"Agree\",\"Disagree\",..: 1 1 2 1 1 1 4 1 2 1 ...\n $ Knowledge_5         : Factor w/ 5 levels \"Agree\",\"Disagree\",..: 1 1 3 4 4 1 3 1 2 1 ...\n $ Knowledge_6         : Factor w/ 5 levels \"Agree\",\"Disagree\",..: 4 5 1 1 1 1 1 3 3 5 ...\n $ Knowledge_7         : Factor w/ 5 levels \"Agree\",\"Disagree\",..: 1 1 1 2 4 2 4 3 1 1 ...\n $ Knowledge_8         : Factor w/ 5 levels \"Agree\",\"Disagree\",..: 3 1 3 1 1 1 3 1 2 1 ...\n $ Knowledge_9         : Factor w/ 5 levels \"Agree\",\"Disagree\",..: 3 5 5 3 4 4 2 2 3 4 ...\n $ TimeSearching       : Factor w/ 5 levels \"15-30 minutes a day\",..: 2 2 3 1 4 3 1 2 3 3 ...\n $ TimeAnswering       : Factor w/ 5 levels \"15-30 minutes a day\",..: 3 1 3 2 1 1 4 2 1 1 ...\n $ ProfessionalCloud   : Factor w/ 3 levels \"Cloud only (single or multi-cloud)\",..: 1 2 2 2 2 1 1 1 1 1 ...\n $ ProfessionalQuestion: Factor w/ 9 levels \"A coworker\",\"AI-powered search (free)\",..: 5 1 9 9 1 1 9 8 9 9 ...\n $ Industry            : chr  \"Healthcare\" \"Software Development\" \"Banking/Financial Services\" \"Software Development\" ...\n $ JobSat              : Factor w/ 11 levels \"0\",\"1\",\"2\",\"3\",..: 9 9 6 11 7 10 5 8 8 8 ...\n $ SurveyLength        : Factor w/ 3 levels \"Appropriate in length\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ SurveyEase          : Factor w/ 3 levels \"Difficult\",\"Easy\",..: 2 2 3 2 2 3 2 3 3 2 ...\n $ JobSat_Grouped      : chr  \"High\" \"High\" \"Medium\" \"High\" ...\n\n\n\n\nCode\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(viridis)\nlibrary(maps)\n\n\nWarning: package 'maps' was built under R version 4.4.2\n\n\n\nAttaching package: 'maps'\n\n\nThe following object is masked from 'package:viridis':\n\n    unemp\n\n\nThe following object is masked from 'package:purrr':\n\n    map\n\n\nCode\n# Load map data\nmap_data &lt;- map_data(\"world\")\n\n# Summarize Job Satisfaction data by country\njob_sat_data &lt;- selected %&gt;%\n  filter(!is.na(JobSat_Grouped)) %&gt;% # Remove missing values\n  group_by(Country, JobSat_Grouped) %&gt;%\n  tally() %&gt;%\n  spread(JobSat_Grouped, n, fill = 0) %&gt;%\n  mutate(\n    Total = High + Medium + Low,\n    High_Proportion = High / Total * 100 # Proportion of \"High\" satisfaction\n  )\n\n# Merge map data with summarized job satisfaction data\nmerged_data &lt;- left_join(map_data, job_sat_data, by = c(\"region\" = \"Country\"))\n\n# Plot the choropleth map\nggplot(merged_data, aes(x = long, y = lat, group = group, fill = High_Proportion)) +\n  geom_polygon(color = \"black\", size = 0.1) +\n  scale_fill_viridis(option = \"magma\", direction = -1, name = \"High Job Sat (%)\") +\n  theme_void() +\n  labs(title = \"Job Satisfaction (High) Proportion by Country\")\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Prepare data: Count frequency of combinations of AIThreat and AISent\nai_threat_sentiment &lt;- selected %&gt;%\n  filter(!is.na(AIThreat) & !is.na(AISent)) %&gt;%\n  count(AIThreat, AISent)\n\n# Create a stacked bar plot\nggplot(ai_threat_sentiment, aes(x = AISent, y = n, fill = AIThreat)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"AI Threat Perception vs AI Sentiment\",\n       x = \"AI Sentiment\",\n       y = \"Count\",\n       fill = \"AI Threat\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(viridis)\nlibrary(maps)\n\n# Assume 'selected' is the dataset you're working with\n\n# Step 1: Summarize the average Job Satisfaction by country\njob_sat_data &lt;- selected %&gt;%\n  filter(!is.na(JobSat)) %&gt;%  # Remove rows with missing job satisfaction data\n  group_by(Country) %&gt;%  # Group by country\n  summarise(AvgJobSat = mean(as.numeric(as.character(JobSat)), na.rm = TRUE))  # Calculate average job satisfaction\n\n# Step 2: Get map data\nmap_data &lt;- map_data(\"world\")\n\n# Step 3: Merge the map data with the summarized job satisfaction data\nmerged_data &lt;- left_join(map_data, job_sat_data, by = c(\"region\" = \"Country\"))\n\n# Step 4: Plot the choropleth map\nggplot(merged_data, aes(x = long, y = lat, group = group, fill = AvgJobSat)) +\n  geom_polygon(color = \"black\", size = 0.1) +  # Draw polygons with black borders\n  scale_fill_viridis(option = \"magma\", direction = -1, name = \"Avg Job Sat\") +  # Use 'viridis' color scale for better visibility\n  theme_void() +  # Remove axis and grid lines for a cleaner map\n  labs(title = \"Average Job Satisfaction by Country\")  # Add title\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(viridis)\nlibrary(maps)\n\n# Step 1: Summarize the proportion of people who think AI is a threat by country\nai_threat_data &lt;- selected %&gt;%\n  filter(!is.na(AIThreat)) %&gt;%  # Remove rows with missing data\n  group_by(Country) %&gt;%  # Group by country\n  summarise(\n    ThreatCount = sum(AIThreat == \"Yes\", na.rm = TRUE),  # Count how many think AI is a threat\n    TotalCount = n(),  # Count the total number of responses\n    ProportionThreat = ThreatCount / TotalCount * 100  # Calculate the proportion\n  )\n\n# Step 2: Get map data\nmap_data &lt;- map_data(\"world\")\n\n# Step 3: Merge the map data with the summarized AI threat data\nmerged_data &lt;- left_join(map_data, ai_threat_data, by = c(\"region\" = \"Country\"))\n\n# Step 4: Plot the choropleth map\nggplot(merged_data, aes(x = long, y = lat, group = group, fill = ProportionThreat)) +\n  geom_polygon(color = \"black\", size = 0.1) +  # Draw polygons with black borders\n  scale_fill_viridis(option = \"magma\", direction = -1, name = \"AI Threat Proportion (%)\") +  # Use 'viridis' color scale\n  theme_void() +  # Remove axis and grid lines for a cleaner map\n  labs(title = \"Proportion of People Who Think AI is a Threat by Country\")  # Add title",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  }
]