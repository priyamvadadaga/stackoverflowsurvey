[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "StackOverflow 2024 Survey Analysis",
    "section": "",
    "text": "1 Introduction\nBefore OpenAI and other LLMs were built, StackOverflow was the go-to source for developers to have their questions answered. In May 2024 over 65,000 developers responded to Stack Overflow’s annual survey about coding, working, AI and how they feel about the industry. This data can provide valuable insights into the current state of the tech industry. As individuals who work in tech or aim to work in tech, understanding these trends is both interesting and essential These insights are crucial for understanding how the industry is evolving and how developers feel about the tools, skills, and environments shaping their work.\nQuestions we’re interested in:\n\nDemographics of respondents: to understand the landscape of users StackOverflow caters to\nPerspectives on AI: to understand developers’ views on AI in the workplace, especially in the world of generative AI as a threat to certain jobs\nStackOverflow usage: With the advent of GPT, LLama and other LLM’s, how developers’ perspectives on more “traditional” sources like StackOverflow are changing and whether it still adequately meets their needs.\n\n(As we explore the data further and discover patterns, we will refine and update our research questions.)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nThis is the link from which the data set has been obtained: Stack Overflow Survey 2024\nEvery May since 2011, Stack Overflow conducts an annual survey. The 2024 survey included data about coding, working, AI and Stack Overflow users’ profiles and perceptions in these domains. The data is collected by Stack Overflow via a Qualtrics survey, and is updated on a yearly basis. The survey follows a questionnaire style with different types of questions including single-choice, multi-select, and Likert scale questions, ranking scale, boolean and text-based.\nThe May 2024 survey had over 65,000 respondents. Stack Overflow publishes results as a data table with 114 features (engineered from 87 questions) and 65,437 rows. It additionally publishes a schema and the questionnaire itself.\nOne concern in terms of parsing is with regards to multi-select questions. Parsing these either result in adding multiple columns which will have many missing values or parsing them in all possible combinations which has little interpretability. Hence, to begin, we limit the inputs to our analysis to the other question types. Additionally, we went through the schema and have picked questions whose responses are relevant to our research questions.\nFinally, the data is downloaded into the ‘data’ folder and is imported using read.csv in R.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(dplyr)\n\nsurvey &lt;- read.csv('data/survey_results_public.csv')\nschema &lt;- read.csv('data/survey_results_schema.csv')\n\n# ncol(survey)\n# nrow(survey)\n\nkeep &lt;- c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'YearsCode', 'YearsCodePro', 'DevType', 'Country', 'ConvertedCompYearly', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'WorkExp', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'Industry', 'JobSat', 'SurveyLength', 'SurveyEase')\n\n\nselected &lt;- survey |&gt; dplyr::select(all_of(keep))\n\n# colSums(is.na(selected))\n# colMeans(is.na(selected)) * 100\n\nselected &lt;- selected |&gt;\n  mutate(across(c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'DevType', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'JobSat', 'SurveyLength', 'SurveyEase'), as.factor))\n\n\n\n\nCode\nlibrary(ggplot2)\nmissing_counts &lt;- colSums(is.na(selected))\nmissing_percent &lt;- (missing_counts / nrow(selected)) * 100\nmissing_df &lt;- data.frame(\n  column = names(missing_counts),\n  missing_percent = missing_percent\n)\nmissing_df$column &lt;- factor(missing_df$column, levels = missing_df$column)\n\nggplot(missing_df, aes(x = column, y = missing_percent)) +\n  geom_bar(stat = \"identity\", fill='skyblue') +\n  labs(\n    title = \"Percentage of Missing Values per Column\",\n    x = \"Columns\",\n    y = \"Missing Values (%)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size=8)) +\n  scale_y_continuous(limits = c(0, 100))\n\n\n\n\n\n\n\n\n\nWe first look at the percentage of missing values in each of our selected columns. As is expected from an online questionnaire, there is a very high number of missing values with multiple columns crossing the 50% threshold as well. We observe that the ‘Check’ column, which was just a check to ensure that the participant was paying attention to the survey has zero missing values. Thus, we do not eliminate any rows based on this check. We also notice that the series of ‘Knowledge_’ questions, which all serve as part of a Likert-scale question have high missing values. These are probably a result of people skipping the question entirely.\nTo further check if there are any correlations between not answering certain types of questions, we plot a heatmap of correlations between missing values. We cannot compute correlations for Age, Check, and MainBranch since these questions have have no missing values.\n\n\nCode\nlibrary(reshape2)\n\n\n\nAttaching package: 'reshape2'\n\n\nThe following object is masked from 'package:tidyr':\n\n    smiths\n\n\nCode\nmissing_matrix &lt;- is.na(selected) * 1\nmissing_corr &lt;- cor(missing_matrix)\n\n\nWarning in cor(missing_matrix): the standard deviation is zero\n\n\nCode\nmissing_corr_melted &lt;- melt(missing_corr)\n\nggplot(missing_corr_melted, aes(Var1, Var2, fill = value)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient2(\n    low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0,\n    limit = c(-1, 1), space = \"Lab\", name = \"Correlation\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size=6),\n    axis.text.y = element_text(size=6)\n  ) +\n  labs(title = \"Correlation of Missing Values\", x = \"Columns\", y = \"Columns\")\n\n\n\n\n\n\n\n\n\nWe observe that, typically, blocks of questions have missing values. For instance, it seems that missing values are correlated in the professional-related questions, i.e. from the column ICorPM until the industry question. These are perhaps a result of the individual being a student or just a hobby-developer. Similarly, another block of correlation is observed for the AI-related questions. Thus, it seems that perhaps, when skipping, individuals skipped certain lines of questioning entirely.\nWe believe that we can retain value by keeping these rows with missing values since perhaps the missing values form clusters of individuals. We explore one other cause of missing values - fatigue. To check this, we plot the percent missing values over the questions in order that they were answered, faceted on their answer to one of the last questions – “How do you feel about the length of the survey this year?”\n\n\nCode\nselected$SurveyLength &lt;- fct_na_value_to_level(selected$SurveyLength)\n\nmissing_values &lt;- selected %&gt;%\n  group_by(SurveyLength) %&gt;%\n  summarise(across(everything(), ~ mean(is.na(.)))) %&gt;%\n  pivot_longer(cols = -SurveyLength, names_to = \"question\", values_to = \"missing_proportion\")\n\nmissing_values &lt;- missing_values %&gt;%\n  left_join(schema, by = c(\"question\" = \"qname\"))\n\nggplot(missing_values, aes(x = question, y = missing_proportion)) +\n  geom_line(group = 1, color = \"darkgrey\", size = 0.5) +\n  geom_point(aes(color = force_resp), size = 1.5) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = -0.01, size = 6)) +\n  labs(x = \"Survey Question\", y = \"Proportion of Missing Values\",\n       title = \"Missing Data Across Survey Questions by SurveyLength\",\n       color = \"Required Question\") +\n  facet_wrap(~ SurveyLength)\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nWe notice, as a general pattern, that the missing values have a somewhat upward trend as users progressed in the survey. As expected, the highest likelihood of missing values is when the last question is unanswered. Interestingly, those that thought the survey was “Too Short” had a higher proportion of missing values compared to those that thought it was “Too long”. Although somewhat counter intuitive, perhaps it is the fatigue from actually answering the questions that results in answering “Too long”, while not answering leads to believing it was too short.\nWe additionally look at data on whether the question is a required question. We notice that certain non-required questions also have very few missing values, indicating user keenness on answering these questions, such as their current development type (i.e. job) and questions regarding their experience with Stack Overflow. We also notice how even certain required questions have high missing values, which perhaps indicates a systemic flaw. We are considering dropping the rows where a required question was not answered, since this likely indicates an incomplete survey that was wrongly submitted.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(dplyr)\n\nsurvey &lt;- read.csv('data/survey_results_public.csv')\nschema &lt;- read.csv('data/survey_results_schema.csv')\n\n# ncol(survey)\n# nrow(survey)\n\nkeep &lt;- c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'YearsCode', 'YearsCodePro', 'DevType', 'Country', 'ConvertedCompYearly', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'WorkExp', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'Industry', 'JobSat', 'SurveyLength', 'SurveyEase')\n\n\nselected &lt;- survey |&gt; dplyr::select(all_of(keep))\n\n# colSums(is.na(selected))\n# colMeans(is.na(selected)) * 100\n\nselected &lt;- selected |&gt;\n  mutate(across(c('MainBranch', 'Age', 'RemoteWork', 'Check', 'EdLevel', 'DevType', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', 'AISelect', 'AISent', 'AIAcc', 'AIComplex', 'AIThreat', 'ICorPM', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'TimeSearching', 'TimeAnswering', 'ProfessionalCloud', 'ProfessionalQuestion', 'JobSat', 'SurveyLength', 'SurveyEase'), as.factor))\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(ggalluvial)\nlibrary(dplyr)\n\nAIThreat_order &lt;- c('No', 'Unsure', 'Yes')\nselected$AIThreat &lt;- factor(selected$AIThreat, levels = AIThreat_order, ordered = TRUE)\n\nAISent_order &lt;- c('Unsure', 'Very unfavorable', 'Unfavorable', 'Indifferent', 'Favorable', 'Very favorable')\nselected$AISent &lt;- factor(selected$AISent, levels = AISent_order, ordered = TRUE)\n\nAIComplex_order &lt;- c('Very poor at handling complex tasks', 'Bad at handling complex tasks', 'Neither good or bad at handling complex tasks', 'Good, but not great at handling complex tasks', 'Very well at handling complex tasks')\nselected$AIComplex &lt;- factor(selected$AIComplex, levels = AIComplex_order, ordered = TRUE)\n\nAIAcc_order &lt;- c('Highly distrust', 'Somewhat distrust', 'Neither trust nor distrust', 'Somewhat trust', 'Highly trust')\nselected$AIAcc &lt;- factor(selected$AIAcc, levels = AIAcc_order, ordered = TRUE)\n\n# Clean data to remove rows with NA values\nfiltered_data &lt;- selected %&gt;%\n  filter(MainBranch == \"I am a developer by profession\") %&gt;%\n  filter(!is.na(AISelect) & !is.na(AISent) & !is.na(AIAcc) & !is.na(AIComplex) & !is.na(AIThreat))\n\n\n\n\nCode\nggplot(filtered_data,\n       aes(axis1 = AIThreat, axis2 = AIComplex, axis3 = AISent, axis4 = AIAcc)) +\n  geom_alluvium(aes(fill = AIAcc)) +\n  geom_stratum(aes(fill = AIAcc), color = \"black\", size = 0.5) +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum)), size = 2.5, color = \"black\") +\n  scale_x_discrete(limits = c(\"AIThreat\", \"AIComplex\", \"AISent\", \"AIAcc\"),\n                   expand = c(0.15, 0.15)) +\n  scale_fill_brewer(palette = \"RdYlBu\") +\n  theme_void() +\n  theme(\n    strip.text = element_text(size = 10),\n    axis.text = element_text(size = 8),\n    axis.title = element_text(size = 10),\n    plot.title = element_text(size = 14)\n  ) +\n  ggtitle(\"Alluvial Diagram for Developers\")\n\n\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\n\n\nWarning: Computation failed in `stat_stratum()`.\nCaused by error in `switch()`:\n! EXPR must be a length 1 vector\n\n\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  }
]